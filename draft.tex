% \documentclass{llncs}
\documentclass[10pt,conference,letterpaper,twocolumn]{IEEEtran}

\usepackage[usenames,dvipsnames]{color}

\usepackage{latexsym}
\usepackage{amsxtra} 
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{pslatex}
\usepackage{epsfig}
\usepackage{wrapfig}
\usepackage{paralist}
\usepackage{graphics}
\usepackage{stmaryrd}
\usepackage{txfonts}
\usepackage{framed}
\usepackage{makecell}
\usepackage{url}
\usepackage{tikz}
\usetikzlibrary{automata,positioning, calc}
\usepackage[inline,shortlabels]{enumitem}

\usepackage{proof}

\usepackage{algorithm}
\usepackage{algorithmicx}
\usepackage[noend]{algpseudocode}

\usepackage[draft]{commenting}

\pagestyle{plain}

\include{commands}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\title{The Impact of Alternation}

\author{Radu Iosif and Xiao Xu \\
Verimag/CNRS/Universit\'e de Grenoble Alpes\\
Email: \{Radu.Iosif,Xiao.Xu\}@univ-grenoble-alpes.fr}

\maketitle

\begin{abstract}
Alternating automata have been widely used to model and verify systems
that handle data from finite domains, such as communication protocols
or hardware. The main advantage of the alternating model of
computation is that complementation is possible in linear time, thus
allowing to concisely encode trace inclusion problems that occur often
in verification. In this paper we consider alternating automata over
infinite alphabets, whose transition rules are formulae in a combined
theory of booleans and some infinite data domain, that relate past and
current values of the data variables. The data theory is not fixed,
but rather it is a parameter of the class. We show that union,
intersection and complementation are possible in linear time in this
model and, though the emptiness problem is undecidable, we provide two
efficient semi-algorithms, inspired by two state-of-the-art
abstraction refinement model checking methods: lazy predicate
abstraction \cite{HJMS02} and the \impact~ semi-algorithm
\cite{mcmillan06}. We have implemented both methods and report the
results of an experimental comparison.
\end{abstract}

\section{Introduction}

\section{Preliminaries}

A \emph{signature} $\sig = (\ssorts{\sig},\sfuns{\sig})$ consists of a
set $\ssorts{\sig}$ of \emph{sort symbols} and a set $\sfuns{\sig}$ of
sorted \emph{function symbols}. To simplify the presentation, we
assume w.l.o.g. that $\ssorts{\sig}$ consists of two distinct sorts
$\Data$ and $\Bool$ and each function symbol $f \in \sfuns{\sig}$ has
$\#(f) \geq 0$ arguments of sort $\Data$ and return value $\sigma(f)
\in \ssorts{\sig}$. If $\#(f)=0$ then $f$ is a \emph{constant}. We
consider the constants $\top$ and $\bot$ of sort $\Bool$.

We consider an infinite countable set of \emph{variables} $\vars$,
where each $x \in \vars$ has an associated sort $\sigma(x)$. Terms are
defined recursively: a term $t$ of sort $\sigma(t)=S$ is a variable $x
\in \vars$ where $\sigma(x)=S$, or $f(t_1,\ldots,t_{\#(f)})$ where
$t_1,\ldots,t_{\#(f)}$ are terms of sort $\Data$ and $\sigma(f)=S$. An
\emph{atom} is a term of sort $\Bool$ or an equality $t \teq s$
between two terms of sort $\Data$. A \emph{literal} is an atom or its
negation. A \emph{formula} is an existentially quantified combination
of atoms using disjunction $\vee$, conjunction $\wedge$ and negation
$\neg$ and we write $\phi \rightarrow \psi$ for $\neg\phi \vee \psi$.

We denote by $\fv{S}{\phi}$ the set of free (i.e.\ not under the scope
of an existential quantifier) variables of sort $S$ in $\phi$ and
write $\fv{}{\phi}$ for $\bigcup_{S \in \set{\Data,\Bool}}
\fv{S}{\phi}$. For a variable $x \in \fv{}{\phi}$ and a term $t$ such
that $\sigma(t) = \sigma(x)$, let $\phi[t/x]$ be the result of
replacing each occurrence of $x$ by $t$. For indexed sets
$\vec{t}=\set{t_1,\ldots,t_n}$ and $\vec{x}=\set{x_1,\ldots,x_n}$, we
write $\phi[\vec{t}/\vec{x}]$ for the formula obtained by
simultaneously replacing $x_i$ with $t_i$ in $\phi$, for all
$i=1,\ldots,n$.
%
%% A formula is in positive normal form (PNF) if negation occurs only
%% within literals and in disjunctive normal form (DNF) if it is a
%% disjunction of conjunctions of literals $\bigvee_{i=1}^N
%% \bigwedge_{j=1}^{M_i} \ell_{ij}$.
%
The size of a formula $\phi$, denoted as $\len{\phi}$, is the number
of symbols occuring in it.

An \emph{interpretation} $\I$ maps\begin{inparaenum}[(1)]
\item the sort $\Data$ into a non-empty set $\Data^\I$, 
%
\item the sort $\Bool$ into the set $\booli = \set{\true,\false}$, where
  $\top^\I = \true$, $\bot^\I = \false$, and
%
\item each function symbol $f$ into a total function $f^\I :
  (\Data^\I)^{\#(f)} \rightarrow \sigma(f)^I$, or an element of
  $\sigma(f)^I$ when $\#(f)=0$.
\end{inparaenum}
Given an interpretation $\I$, a \emph{valuation} $\nu$ maps each
variable $x \in \vars$ into an element $\nu(x) \in \sigma(x)^\I$. For
a term $t$, we denote by $t^\I_\nu$ the value obtained by replacing
each function symbol $f$ by its interpretation $f^\I$ and each
variable $x$ by its valuation $\nu(x)$. For a formula $\phi$, we write
$\I,\nu \models \phi$ if the formula obtained by replacing each term
$t$ in $\phi$ by the value $t^\I_\nu$ is logically equivalent to true.
A formula $\phi$ is \emph{satisfiable} in the interpretation $\I$ if
there exists a valuation $\nu$ such that $\I,\nu \models \phi$, and
\emph{valid} if $\I,\nu \models \phi$ for all valuations $\nu$.  The
\emph{theory} $\theory(\sig,\I)$ is the set of valid formulae written
in the signature $\sig$, with the interpretation $\I$.

Given formulae $\varphi$ and $\psi$, we say that \emph{$\phi$ entails
  $\psi$}, denoted $\phi \models^\I \psi$ iff $\I,\nu \models \varphi$
implies $\I,\nu \models \psi$, for each valuation $\nu$, and $\phi
\eqiff^\I \psi$ iff $\phi \models^\I \psi$ and $\psi \models^\I \phi$.
We omit mentioning the interpretation $\I$ when it is clear from the
context.

\section{Alternating Data Automata}

In the rest of this section we fix an interpretation $\I$ and a finite
alphabet $\Sigma$ of \emph{input events}. Given a finite set $\vec{x}
\subset \vars$ of variables of sort $\Data$, let $\vec{x} \mapsto
\Data^\I$ be the set of valuations of the variables $\vec{x}$ and
$\Sigma[\vec{x}] = \Sigma \times (\vec{x} \mapsto \Data^\I)$ be the
set of \emph{data symbols}. A \emph{data word} (word in the sequel) is
a finite sequence $(a_1,\nu_1)(a_2,\nu_2) \ldots (a_n,\nu_n)$ of data
symbols, where $a_1,\ldots,a_n \in \Sigma$ and $\nu_1,\ldots,\nu_n :
\vec{x} \rightarrow \Data^\I$ are valuations. We denote by
$\varepsilon$ the empty sequence, by $\Sigma^*$ the set of finite
sequences of input events and by $\Sigma[\vec{x}]^*$ the set of data
words over $\vec{x}$.

This definition generalizes the classical notion of words from a
finite alphabet to the possibly infinite alphabet
$\Sigma[\vec{x}]$. Clearly, when $\Data^\I$ is sufficiently large or
infinite, we can map the elements of $\Sigma$ into designated elements
of $\Data^\I$ and use a special variable to encode the input
events. However, keeping $\Sigma$ explicit in the following simplifies
several technical points below, without cluttering the presentation.

Given sets of variables $\vec{b},\vec{x} \subset \vars$ of sort
$\Bool$ and $\Data$, respectively, we denote by
$\Form^+(\vec{b},\vec{x})$ the set of formulae $\phi$ such that
$\fv{\Bool}{\phi} \subseteq \vec{b}$, $\fv{\Data}{\phi} \subseteq
\vec{x}$ and each variable from $\vec{b}$ occurs under an even number
of negations. 

An \emph{alternating data automaton} (ADA or automaton in the sequel)
is a tuple $\A = \tuple{\vec{x},Q,\iota,F,\Delta}$,
where: \begin{compactitem}
%
\item $\vec{x} \subset \vars$ is a finite set of variables of sort
  $\Data$,
%
\item $Q$ is a finite set of variables of sort $\Bool$, called
  \emph{states},
%
\item $\iota \in \Form^+(Q,\emptyset)$ is positive boolean combination
  of states defining the \emph{initial configurations},
%
\item $F \subseteq Q$ is a set of \emph{final states}, and
%
\item $\Delta : Q \times \Sigma \rightarrow
  \Form^+(Q,\overline{\vec{x}}\cup\vec{x})$ is a \emph{transition
    function}, where $\overline{\vec{x}}$ is the set $\{\overline{x}
  \mid x \in \vec{x}\}$.
\end{compactitem}
Intuitively, in each formula $\Delta(q,a)$ describing a transition
rule, the variables $\overline{\vec{x}}$ track the previous and
$\vec{x}$ the current values of the variables of $\A$. Observe
further, that the initial values of the variables are left
unconstrained, as the initial configuration does not contain free
data variables. The size of $\A$ is defined as $\len{\A} = \len{\iota}
+ \sum_{(q,a) \in Q\times\Sigma}\len{\Delta(q,a)}$.

Formally, let $\vec{x}_k = \set{x_k \mid x \in \vec{x}}$, $k\geq0$, be
a set of time-stamped variables. For an input event $a \in \Sigma$ and
a formula $\phi$, we write $\Delta^k(\phi,a)$ for the formula obtained
from $\phi$ by simultaneously replacing each state $q \in
\fv{\Bool}{\phi}$ by the formula
$\Delta(q,a)[\vec{x}_k/\overline{\vec{x}},\vec{x}_{k+1}/\vec{x}]$, for
all $k\geq0$. Given a word $w = (a_1,\nu_1)(a_2,\nu_2) \ldots
(a_n,\nu_n)$, the \emph{run} of $\A$ over $w$ is the sequence of
formulae $\phi_0,\phi_1,\ldots,\phi_n$, where $\phi_0 \equiv \iota$
and, for all $k > 0$, we have $\phi_k \equiv
\Delta^k(\phi_{k-1},a_k)$. Next, we slightly abuse notation and write
$\Delta(\iota,a_1,\ldots,a_n)$ for the formula
$\phi_n(\vec{x}_0,\ldots,\vec{x}_n)$ above. We say that $\A$
\emph{accepts} $w$ iff $\I,\nu \models \Delta(\iota,a_1,\ldots,a_n)$,
where $\nu$ is some valuation that maps:\begin{inparaenum}[(1)]
%
\item each $x \in \vec{x}_k$ to $\nu_k(x)$, for all $k\in[1,n]$, 
%
\item each $q \in \fv{\Bool}{\phi_n} \cap F$ to $\top$ and 
%
\item each $q \in \fv{\Bool}{\phi_n} \setminus F$ to $\bot$.
\end{inparaenum}
The language of $\A$ is the set $L(\A)$ of words accepted by $\A$.

In this paper we tackle the following problems: \begin{compactenum}
\item \emph{boolean closure}: given automata $\A_1$ and $\A_2$, both
  with the same set of variables $\vec{x}$, do there exist automata
  $\A_\cup$, $\A_\cap$ and $\overline{\A_1}$ such that $L(\A_\cup) =
  \A_1 \cup \A_2$, $L(A_\cap) = \A_1 \cap \A_2$ and
  $L(\overline{\A_1}) = \Sigma[\vec{x}]^* \setminus L(\A_1)$ ?
%
\item \emph{emptiness}: given an automaton $\A$, is it the case that
  $L(\A) = \emptyset$ ?
\end{compactenum}

It is well known that other problems, such as \emph{universality}
(given automaton $\A$ with variables $\vec{x}$, does $L(\A) =
\Sigma[\vec{x}]^*$?) and \emph{inclusion} (given automata $\A_1$ and
$\A_2$ with the same set of variables, does $L(\A_1) \subseteq
L(\A_2)$?) can be reduced to the above problems. Observe furthermore
that we do not consider cases in which the sets of variables in the
two automata differ. An interesting problem in this case would be: given
automata $\A_1$ and $\A_2$, with variables $\vec{x}_1$ and
$\vec{x}_2$, respectively, such that $\vec{x}_1 \subseteq \vec{x}_2$,
does $L(\A_1) \subseteq \proj{L(\A_2)}{\vec{x}_1}$, where
$\proj{L(\A_2)}{\vec{x}_1}$ is the projection of the set of words
$L(\A_2)$ onto the variables $\vec{x}_1$? This problem is considered
as future work.

\subsection{Boolean Closure}

Given a set $Q$ of boolean variables and a set $\vec{x}$ of variables
of sort $\Data$, for a formula $\phi \in \Form^+(Q,\vec{x})$, with no
negated occurrences of the boolean variables, we define the formula
$\overline{\phi} \in \Form^+(Q,\vec{x})$ recursively on the structure
of $\phi$:
\[\begin{array}{lclclcl}
\overline{\phi_1 \vee \phi_2} & \equiv & \overline{\phi_1} \wedge \overline{\phi_2} && 
\overline{\phi_1 \wedge \phi_2} & \equiv & \overline{\phi_1} \vee \overline{\phi_2} \\ 
\overline{\neg\phi} & \equiv & \neg \overline{\phi} \text{ if $\phi$ not atom} &&
\overline{\phi} & \equiv & \phi \text{ if $\phi \in Q$} \\
\overline{\phi} & \equiv & \neg\phi \text{ if $\phi \not\in Q$ atom}
\end{array}\]
It is easy to check that $\len{\overline{\phi}} = \len{\phi}$, for
every formula $\phi \in \Form^+(Q,\vec{x})$. If $\phi$ does not
contain boolean variables, then $\overline{\phi}$ and $\neg\phi$ are
equivalent, and in general:

\begin{proposition}\label{prop:overline}
  Given a formula $\phi \in \Form^+(Q,\vec{x})$ and a valuation $\nu$
  mapping each $q \in Q$ to a value $\nu(q) \in \booli$ and each $x \in
  \vec{x}$ to a value $\nu(x) \in \Data^\I$, let $\nu'$ be the
  valuation that assigns each $q \in Q$ the value $\neg\nu(q)$ and
  each $x \in \vec{x}$ the value $\nu(x)$. Then we have 
  $\I,\nu \models \phi$ if and only if $\I,\nu' \not\models \overline{\phi}$. 
\end{proposition}
\proof{Immediate, by induction on the structure of $\phi$. \qed}

In the following let $\A_i =
\tuple{\vec{x},Q_i,\iota_i,F_i,\Delta_i}$, for $i=1,2$, where
w.l.o.g. we assume that $Q_1 \cap Q_2 = \emptyset$. We define: 
\[\begin{array}{rcl}
\A_\cup & = & \tuple{\vec{x},Q_1\cup Q_2,\iota_1 \vee \iota_2,F_1\cup F_2,\Delta_1\cup\Delta_2} \\ 
\A_\cap & = & \tuple{\vec{x},Q_1\cup Q_2,\iota_1 \wedge \iota_2, F_1\cup F_2, \Delta_1\cup\Delta_2} \\ 
\overline{\A_1} & = & \langle \vec{x},Q_1,\iota_1,Q_1\setminus F_1,\overline{\Delta_1} \rangle
\end{array}\] 
where $\overline{\Delta_1}(q,a) \equiv \overline{\Delta_1(q,a)}$, for
all $q \in Q_1$ and $a \in \Sigma$. The following lemma shows the
correctness of the above definitions:

\begin{lemma}\label{lemma:closure}
  Given automata $\A_i = \tuple{\vec{x},Q_i,\iota_i,F_i,\Delta_i}$,
  for $i=1,2$, such that $Q_1 \cap Q_2 = \emptyset$, we have
  $L(\A_\cup) = L(\A_1) \cup L(\A_2)$, $L(\A_\cap) = L(\A_1) \cap
  L(\A_2)$ and $L(\overline{\A_1}) = \Sigma[\vec{x}]^* \setminus
  L(\A_1)$.
\end{lemma}
\proof{ We prove $L(\A_\cup) = L(\A_1) \cup L(\A_2)$ first, the proof
  for $\A_\cap$ being analogous. Let $w = (a_1,\nu_1) \ldots
  (a_n,\nu_n)$ be a word, where $n=0$ corresponds to the empty
  word. We prove by induction on $n\geq0$ that $\Delta(\iota_1 \vee
  \iota_2,a_1\ldots a_n) \eqiff \Delta(\iota_1,a_1\ldots a_n) \vee
  \Delta(\iota_2,a_1\ldots a_n)$. The case $n=0$ follows from the
  definition of the initial configuration of $\A_\cup$. For the
  inductive step $n>0$, $\Delta(\iota_1 \vee \iota_2,a_1\ldots a_n)$
  is obtained from $\Delta(\iota_1 \vee \iota_2,a_1\ldots a_{n-1})$ by
  replacing each variable $q \in \fv{\Bool}{\Delta(\iota_1 \vee
    \iota_2,a_1\ldots a_{n-1})}$ with
  $\Delta(q,a_n)[\vec{x}_{n-1}/\overline{\vec{x}},\vec{x}_n/\vec{x}]$,
  denoted $\Delta^n(\Delta(\iota_1 \vee \iota_2,a_1\ldots
  a_{n-1}),a_n)$. Since by induction hypothesis, $\Delta(\iota_1 \vee
  \iota_2,a_1\ldots a_{n-1}) \eqiff \Delta(\iota_1,a_1\ldots a_{n-1})
  \vee \Delta(\iota_2,a_1\ldots a_{n-1})$, we obtain:
  \[\begin{array}{ll}
  \Delta^n(\Delta(\iota_1 \vee \iota_2,a_1\ldots a_{n-1}),a_n) & \eqiff \\
  \Delta^n(\Delta(\iota_1,a_1\ldots a_{n-1}),a_n) \vee \Delta^n(\Delta(\iota_2,a_1\ldots a_{n-1}),a_n) & \eqiff \\
  \Delta(\iota_1,a_1\ldots a_{n}) \vee \Delta(\iota_2,a_1\ldots a_{n}) \enspace.
  \end{array}\] 
  To prove $L(\overline{\A_1}) = \Sigma[\vec{x}]^* \setminus L(\A_1)$,
  let $w = (a_1,\nu_1) \ldots (a_n,\nu_n)$ be a word and show that
  $\overline{\Delta}(\iota_1,a_1 \ldots a_n) =
  \overline{\Delta(\iota_1,a_1 \ldots a_n)}$ by induction on
  $n\geq0$. The case $n=0$ is immediate, because $\fv{}{\iota_1}
  \subseteq Q$ and thus $\overline{\iota_1} = \iota_1$. For the case
  $n>0$, we compute:
  \[\begin{array}{lcl}
  \overline{\Delta}^n(\overline{\Delta}(\iota_1,a_1\ldots a_{n-1}),a_n) & \eqiff & \text{ by induction hypothesis} \\
  \overline{\Delta}^n(\overline{\Delta(\iota_1,a_1\ldots a_{n-1})},a_n) & \eqiff & \text{ by the definition of $\overline{\phi}$} \\
  \overline{\Delta(\iota_1,a_1\ldots,a_n)}
  \end{array}\]
  Let $\nu,\nu' : (Q \cup \bigcup_{i=0}^n\vec{x}_i) \rightarrow (\booli
  \cup \Data^\I)$ be valuations such that: \begin{compactitem}
  \item $\nu(q) = \top$ and $\nu'(q) = \bot$, for each $q \in F$, 
    %
  \item $\nu(q) = \bot$ and $\nu'(q) = \top$, for each $q \in Q \setminus F$, 
    %
  \item $\nu(x) = \nu'(x)$, for each $x \in \vec{x}_0$, 
    %
  \item $\nu(x) = \nu'(x) = \nu_i(x)$, for each $x \in \vec{x}_i$ and each $i
    \in [1,n]$.
  \end{compactitem}
  By Proposition \ref{prop:overline}, we have $\I,\nu \models
  \Delta(\iota_1,a_1 \ldots a_n) \iff \I,\nu' \not\models
  \overline{\Delta(\iota_1,a_1 \ldots a_n)} \iff \I,\nu' \not\models
  \overline{\Delta}(\iota_1,a_1 \ldots a_n)$. Thus $w \in L(\A_1) \iff
  w \not\in L(\overline{\A_1})$, i.e. $L(\overline{\A_1}) =
  \Sigma[\vec{x}]^* \setminus L(\A_1)$. \qed}

It is easy to see that $\len{\A_\cup} = \len{\A_\cap} = \len{\A_1} +
\len{\A_2}$ and $\len{\overline{\A}} = \len{\A}$, thus the automata
for the boolean operations, including complementation, can be built in
linear time. This is not surprising, as linear time intersection and
complementation are also possible for alternating automata over finite
alphabets \cite{ChandraKozenStockmeyer81}.

\section{Antichains and Interpolants for Emptiness}

Unlike the boolean closure properties, showed to be effectively
decidable (Lemma \ref{lemma:closure}), the emptiness problem is
undecidable, even in very simple cases. For instance, if $\Data^\I$ is
the set of positive integers, an ADA can simulate an Alternating
Vector Addition System with States (AVASS) \cite{LazicSchmitz14} using
only atoms $x \geq k$ and $x = \overline{x} + k$, for $k \in \zed$,
with the classical interpretation of the function symbols on
integers. Since reachability of a control state is undecidable for
AVASS \cite{LINCOLN92}, the emptiness problem is undecidable for ADA.

Consequently, we give up on the guarantee for termination and build
semi-algorithms that meet the requirements below: \begin{compactenum}[(i)]
\item given an automaton $\A$, if $L(\A) \neq\emptyset$, the procedure
  will terminate and return a word $w \in L(\A)$, and
%
\item if the procedure terminates without returning such a word, then
  $L(\A) = \emptyset$.
\end{compactenum}

Let us fix an automaton $\A = \tuple{\vec{x},Q,\iota,F,\Delta}$ whose
(finite) input event alphabet is $\Sigma$, for the rest of this
section. Given a formula $\phi \in \Form^+(Q,\vec{x})$ and an input
event $a \in \Sigma$, we define the \emph{post-image} function
$\Post{\A}(\phi,a) \equiv \exists \overline{\vec{x}} ~.~
\Delta(\phi[\overline{\vec{x}}/\vec{x}], a) \in \Form^+(Q,\vec{x})$,
mapping each formula in $\Form^+(Q,\vec{x})$ to a formula defining the
effect of reading the event $a$.

We generalize the post-image function to finite sequences of input
events, as follows, for any $u \in \Sigma^*$:
\[\begin{array}{l}
\Post{\A}(\phi,\varepsilon) \equiv \phi \hspace*{5mm} \Post{\A}(\phi,ua) \equiv \Post{\A}(\Post{\A}(\phi,u),a) \\
\Accept{\A}(u) \equiv \Post{\A}(\iota,u) \wedge \bigwedge_{q \in Q \setminus F} (q \rightarrow \bot)
\end{array}\]
Then the emptiness problem for $\A$ becomes: does there exist $u \in
\Sigma^*$ such that the formula $\Accept{\A}(u)$ is satisfiable?
Observe that, since we ask a satisfiability query, the final states of
$\A$ need not be constrained\footnote{ Since each state occurs
  positively in $\Accept{\A}(u)$, this formula has a model iff it has
  a model with every $q \in F$ set to true.}. A na\"ive semi-algorithm
enumerates all finite sequences and checks the satisfiability of
$\Accept{\A}(u)$ for each $u \in \Sigma^*$, using a decision procedure
for the theory $\theory(\sig,\I)$.

Since no boolean variable from $Q$ occurs under negation in $\phi$, it
is easy to prove the following monotonicity property: given two
formulae $\phi,\psi \in \Form^+(Q,\vec{x})$ if $\phi \models \psi$
then $\Post{\A}(\phi,u) \models \Post{\A}(\psi,u)$, for any $u \in
\Sigma^*$. This suggest an improvement of the above semi-algorithm,
that enumerates and stores only a set $U \subseteq \Sigma^*$ for which
$\set{\Post{\A}(\phi,u) \mid u \in U}$ forms an
\emph{antichain}\footnote{Given a partial order $(D,\preceq)$ an
  antichain is a set $A \subseteq D$ such that $a \not\preceq b$ for
  any $a,b \in A$.} w.r.t. the entailment partial order. This is
because, for any $u,v \in \Sigma^*$, if $\Post{\A}(\iota,u) \models
\Post{\A}(\iota,v)$ and $\Accept{\A}(uw)$ is satisfiable, then
$\Post{\A}(\iota,uw) \models \Post{\A}(\iota,vw)$, thus
$\Accept{\A}(vw)$ is satisfiable as well, and there is no need for
$u$, since the non-emptiness of $\A$ can be proved using $v$
alone. However, the antichain-based semi-algorithm diverges in a large
number of cases, since infinite antichains exist in many
interpretations, e.g.\ $q \wedge x \teq 0,~ q \wedge x \teq 1, \ldots$
for $\Data^\I = \nat$.

A \emph{safety invariant} for $\A$ is a function $\Inv : (Q \mapsto
\booli) \rightarrow 2^{\vec{x} \mapsto \Data^\I}$ such that, for every
boolean valuation $\beta : Q \rightarrow \booli$, every valuation $\nu
: \vec{x} \mapsto \Data^\I$ of the data variables and every finite
sequence $u \in \Sigma^*$ of input events, the following
hold: \begin{compactenum}
%% \item $\beta \models \iota \Rightarrow \nu_0 \in \Inv(\beta)$, where
%%   $\nu_0(x) = \mathbf{0}$, for all $x \in \vec{x}$.
%
\item\label{it1:inv} $\I,\beta \cup \nu \models \Post{\A}(\iota,u)
  \Rightarrow \nu \in \Inv(\beta)$, and
%
\item\label{it2:inv} $\nu \in \Inv(\beta) \Rightarrow \I,\beta \cup
  \nu \not\models \Accept{\A}(u)$.
\end{compactenum}
A formula $\phi(Q,\vec{x})$ \emph{defines} $\Inv$ iff for all $\beta:
Q \rightarrow \booli$ and $\nu : \vec{x} \rightarrow \Data^\I$,
$\I,\beta\cup\nu \models \phi$ if and only if $\nu \in
\Inv(\beta)$. If $\Inv$ satisfies only the first point above, we call
it an \emph{invariant}. Intuitively, a safety invariant maps every
boolean valuation into a set of data valuations, that contains the
initial configuration $\iota = \Post{\A}(\iota,\varepsilon)$, whose
data variables are unconstrained, over-approximates the set of
reachable valuations (\ref{it1:inv}) and excludes the valuations
satisfying the acceptance condition (\ref{it2:inv}).

\begin{lemma}\label{lemma:safety-invariant}
  For any automaton $\A$, we have $L(\A) = \emptyset$ if and only if
  $\A$ has a safety invariant.
\end{lemma}
\proof{ Let $\A = \tuple{\vec{x},Q,\iota,F,\Delta}$ in the following.
  ``$\Leftarrow$'' This direction is trivial. ``$\Rightarrow$'' We
  define $\Inv : (Q \mapsto \booli) \rightarrow 2^{\vec{x} \mapsto
    \Data^\I}$ as follows. For each $\beta : Q \rightarrow \booli$,
  let $\Inv(\beta) = \{\nu : \vec{x} \rightarrow \Data^\I \mid \exists
  u \in \Sigma^* ~.~ \beta\cup\nu \models
  \Post{\A}(\iota,u)\}$. Checking that $\Inv$ is a safety invariant is
  straightforward. \qed}

Turning back to the issue of divergence of language emptiness
semi-algorithms in the case $L(\A) = \emptyset$, we can observe that
an enumeration of input sequences $u_1,u_2,\ldots \in \Sigma^*$ can
stop at step $k$ as soon as $\bigvee_{i=1}^k \Post{\A}(\iota,u_i)$
defines a safety invariant for $\A$. Although this condition can be
effectively checked using a decision procedure for the theory
$\theory(\sig,\I)$, there is no guarantee that this check will ever
succeed.

The solution we adopt is abstraction to ensure the termination of
invariant computations. However, it is worth pointing out from the
start that abstraction alone will only allow us to build invariants
that are not necessarily safety invariants. To meet the latter
condition, we resort to counterexample guided abstraction refinement
(CEGAR).

Formally, let $\preds$ be a finite set of formulae with variables from
$Q \cup \vec{x}$, such that $\bot \in \preds$ and the variables in $Q$
can now occur negated within the formulae $\phi \in \preds$. We fix
$\preds$ from now on and refer to these formulae as
\emph{predicates}. Given a formula $\phi$, we denote by $\abs{\phi}
\equiv \bigwedge \set{\pi \in \preds \mid \phi \models \pi}$ the
abstraction of $\phi$ w.r.t. the predicates in $\preds$. The abstract
version of the post-image and acceptance condition are defined as
follows, for any $u \in \Sigma^*$:
\[\begin{array}{l}
\AbsPost{\A}(\phi,\varepsilon) \equiv \phi \hspace*{5mm}
\AbsPost{\A}(\phi,ua) \equiv \abs{(\Post{\A}(\AbsPost{\A}(\phi,u),a))} \\
\AbsAccept{\A}(u) \equiv \AbsPost{\A}(\iota,u) \wedge \bigwedge_{q \in Q \setminus F} 
(q \rightarrow \bot)
\end{array}\]
\begin{lemma}\label{lemma:abstract-invariant}
  For any bijection $\mu : \nat \rightarrow \Sigma^*$, there exists
  $k>0$ such that $\bigvee_{i=1}^k \AbsPost{\A}(\iota,\mu(i))$ defines
  an invariant for $\A$. 
\end{lemma}
\proof{ It is sufficient to show that there exists $k\geq0$ such that for
  all $u \in \Sigma^*$ there exists $i \in [0,k]$ such that
  $\Post{\A}(\iota,u) \models \AbsPost{\A}(\iota,\mu(i))$. We have
  $\Post{\A}(\iota,u) \models \AbsPost{\A}(\iota,u)$ for all $u \in
  \Sigma^*$. But since $\preds$ is a finite set, also the set
  $\{\AbsPost{\A}(\iota,u) \mid u \in \Sigma^*\}$ is finite. Thus
  there exists $k \geq 0$ such that, for all $u \in \Sigma^*$ there
  exists $i \in [0,k]$ such that $\AbsPost{\A}(\iota,u) \eqiff
  \AbsPost{\A}(\iota,\mu(i))$, which concludes the proof. \qed}

We are left with fulfilling the second point from the definition of a
safety invariant. To this end, suppose that, for a given set $\preds$
of predicates, the invariant $\abs{\Inv}$, defined by the previous
lemma, meets point (\ref{it1:inv}) but not point (\ref{it2:inv}) from
the definition of invariants, where $\Post{\A}$ and $\Accept{\A}$
replace $\AbsPost{\A}$ and $\AbsAccept{\A}$, respectively. In
other words, there exists a finite sequence $u \in \Sigma^*$ such that
$\nu \in \abs{\Inv}(\beta)$ and $\I,\beta\cup\nu \models
\AbsAccept{\A}(u)$, for some boolean $\beta : Q \rightarrow \booli$
and data $\nu : \vec{x} \rightarrow \Data^\I$ valuations. Such
a $u\in\Sigma^*$ is called a \emph{counterexample}.

Once a counterexample $u$ is discovered, there are two
possibilities. Either\begin{inparaenum}[(i)]
\item $\Accept{\A}(u)$ is satisfiable, in which case $L(\A) \neq \emptyset$, or
\item $\Accept{\A}(u)$ is unsatisfiable, in which case $u$ is called
  \emph{spurious}.
\end{inparaenum}
In the first case, our semi-algorithm stops and returns a witness for
non-emptiness, obtained from the satisfying valuation of
$\Accept{\A}(u)$ and in the second case, we must strenghten the
invariant by excluding from $\abs{\Inv}$ all pairs $(\beta,\nu)$ such
that $\I,\beta\cup\nu \models \AbsAccept{\A}(u)$. This strenghtening
is carried out by adding to $\preds$ several predicates that are
sufficient to exclude the spurious counterexample.

In general, given an unsatisfiable conjunction $\pi \equiv
\phi_1(X_0,X_1) \wedge \phi_2(X_1,X_2) \wedge \ldots \wedge
\phi_n(X_{n-1},X_n)$ of time-stamped variables $X_i = \set{x_i \mid x
  \in X}$ of any sort, a solution of the \emph{interpolation problem}
$\pi$, simply called an \emph{interpolant}, is a tuple $\tuple{I_0(X),
  I_1(X), \ldots, I_n(X)}$ such that:\begin{inparaenum}[(i)]
\item $I_0 \equiv \top$,  
%
\item $I_{i-1}[X_{i-1}/X] \wedge \phi_i(X_{i-1},X_i) \models
  I_i[X_i/X]$, for all $i \in [1,n]$, and
%
\item $I_n \equiv \bot$. 
\end{inparaenum}

\paragraph{\em Remark} 
We deviate from the standard notion of \emph{generalized interpolants}
\cite{mcmillan06}, which requires $\fv{}{I_i} \subseteq \fv{}{\phi_i}
\cap \fv{}{\phi_{i+1}}$, for each $i \in [1,n-1]$, and assume further
that the variables have been already renamed by removing the
time-stamps. \qed

A classical method for abstraction refinement is to add the elements
of the interpolant obtained from a proof of spuriousness to the set of
predicates. This guarantees progress, meaning that the particular
spurious counterexample, from which the interpolant was generated,
will never be revisited in the future. Though not always, in many
practical test cases this progress property eventually yields a safety
invariant.

Given a non-empty spurious counterexample $u = a_1\ldots a_n$, where
$n>0$, we consider the following interpolation problem: 
\begin{eqnarray}\label{eq:interpolation-problem}
\pi(u) & \equiv & \theta_0(Q_0) \wedge \theta_1(Q_0 \cup Q_1,\vec{x}_0
\cup \vec{x}_1) \wedge \ldots \\ 
&& \wedge~ \theta_n(Q_{n-1} \cup Q_n,\vec{x}_{n-1} \cup \vec{x}_n) \wedge \theta_{n+1}(Q_n) \nonumber
\end{eqnarray}
where $Q_k = \set{q_k \mid q \in Q}$, $k \in [0,n]$ are time-stamped
sets of boolean variables corresponding to the set $Q$ of states of
$\A$. The first conjunct $\theta_0(Q_0) \equiv \iota[Q_0/Q]$ is the
initial configuration of $\A$, with every $q \in \fv{\Bool}{\iota}$
replaced by $q_0$. The definition of $\theta_k$, $k\in[1,n]$ uses
\emph{replacement sets} $R_\ell \subseteq Q_\ell$, $\ell\in [0,n]$,
which are defined inductively below: \begin{compactitem}
\item $R_0 = \fv{\Bool}{\theta_0}$ and 
%
\item $\theta_\ell \equiv \bigwedge_{q_{\ell-1}\in R_{\ell-1}}
  (q_{\ell-1} \rightarrow
  \Delta(q,a_\ell)[Q_\ell/Q,\vec{x}_{\ell-1}/\overline{\vec{x}},\vec{x}_\ell/\vec{x}])$
  and $R_\ell = \fv{\Bool}{\theta_\ell} \cap Q_\ell$, for each
  $\ell\in[1,n]$.
\end{compactitem}
Finally, we set $\theta_{n+1}(Q_n) \equiv \bigwedge_{q \in Q \setminus
  F} (q_n \rightarrow \bot)$. The intuition is that $\theta_0, \ldots,
\theta_n$ simulate the run of $\A$ over $u$ and $\theta_{n+1}$ is the
acceptance condition, which forces the last remaining non-final states
to be false. 

We recall that a run of $\A$ over $u$ is a sequence $\phi_0(Q),
\phi_1(Q,\vec{x}_0\cup\vec{x}_1), \ldots,
\phi_n(Q,\vec{x}_0\cup\ldots\cup\vec{x}_n)$, where $\phi_0$ is the
initial configuration $\iota$ and for each $k>0$, $\phi_k$ is obtained
from $\phi_{k-1}$ by replacing each state $q \in
\fv{\Bool}{\phi_{k-1}}$ by the formula $\Delta(q,a_k)$ given by the
transition function of $\A$. Observe that, because the states are
replaced with transition formulae when moving one step in a run, the
formulae thus produced lose track of the control history and are not
directly suitable to producing interpolants that relates states and
data.

The main idea behind the above definition of the interpolation problem
is that we would like to obtain an interpolant $\tuple{\top,I_1(Q),
  I_2(Q,\vec{x}), \ldots, I_{n}(Q,\vec{x}),\bot}$ whose formulae
\emph{combine states with the data constraints that must hold
  locally}, whenever the control reaches a certain boolean
configuration. This association of states with data valuations is
tantamount to defining efficient semi-algorithms, based on lazy
abstraction \cite{HJMS02}. Furthermore, the abstraction defined by the
interpolants generated in this way can also \emph{over-approximate the
  control structure} of an automaton, in addition to the sets of data
values encountered throughout its runs.

The correctness of this interpolation-based abstraction refinement
setup is captured by the progress property below, which guarantees
that adding the formulae of an interpolant for $\pi(u)$ to the set
$\preds$ of predicates suffices to exclude the spurious counterexample
$u$ from future searches.

\begin{lemma}\label{lemma:progress}
  For any non-empty sequence $u = a_1\ldots a_n \in \Sigma^*$
  such that $\Accept{\A}(u)$ is unsatisfiable, the following
  hold: \begin{compactenum}
  \item\label{it1:progress} $\pi(u)$ is unsatisfiable, and
    %
  \item\label{it2:progress} if $\tuple{\top,I_1,\dots,I_{n+1},\bot}$
    is an interpolant for $\pi(u)$ and $\set{I_i \mid i \in[1,n+1]}
    \subseteq \preds$ then $\AbsAccept{\A}(u)$ is unsatisfiable.
  \end{compactenum}
\end{lemma}
\proof{ Let $\pi(u) \equiv \theta_0(Q_0) \wedge \theta_1(Q_0 \cup
  Q_1,\vec{x}_0 \cup \vec{x}_1) \wedge \ldots \wedge \theta_n(Q_{n-1}
  \cup Q_n,\vec{x}_{n-1} \cup \vec{x}_n) \wedge \theta_{n+1}(Q_n)$ in
  the following.

  (\ref{it1:progress}) Assume that $\pi(u)$ is satisfiable and let
  $\beta_0,\ldots,\beta_n$ and $\nu_0,\ldots,\nu_n$ be boolean and
  data valuations for $Q_0,\ldots,Q_n$ and
  $\vec{x}_0,\ldots,\vec{x}_n$, respectively, such that
  $\I,\bigcup_{i=0}^n \beta_i \cup \bigcup_{i=0}^n \nu_i \models
  \pi(u)$. We build a model for $\Accept{\A}(u) \equiv
  \Post{\A}(\iota,u) \wedge \theta_{n+1}[Q/Q_n]$. Let
  $\phi_0,\phi_1,\ldots,\phi_n$ be the run of $\A$ over $u$. We show
  that $\phi_n(Q,\vec{x}_0\cup\ldots\cup\vec{x}_n)$ has a model, by
  induction on $n\geq0$. For the base case $n=0$, $\phi_0 \equiv \iota
  \equiv \theta_0[Q/Q_0]$ has the model $\beta(q) = \beta_0(q_0)$, for
  all $q \in Q$. For the induction step $n > 0$, we assume that
  $\phi_{n-1}(Q,\vec{x}_0\cup\ldots\vec{x}_{n-1})$ has the model
  $\beta \cup \nu_0 \cup \ldots \nu_{n-1}$, where $\beta(q) =
  \beta_{n-1}(q_{n-1})$, for all $q \in Q$. By the definition of
  $\pi(u)$: \[\theta_n \equiv \bigwedge_{q_{n-1} \in
    \fv{\Bool}{\theta_{n-1}} \cap Q_{n-1}} \left(q_{n-1} \rightarrow
  \Delta(q,a_n)[Q_n/Q,\vec{x}_{n-1}/\overline{\vec{x}},\vec{x}_n/\vec{x}]\right)\]

  But since $\I,\beta_{n-1} \cup \beta_n, \nu_{n-1} \cup \nu_n \models
  \theta_n(Q_{n-1}\cup Q_n, \vec{x}_{n-1} \cup \vec{x}_n)$, we have
  that $\I,\beta_n,\nu_{n-1} \cup \nu_n \models
  \Delta(q,a_n)[Q_n/Q,\vec{x}_{n-1}/\overline{\vec{x}},\vec{x}_n/\vec{x}]$,
  for every $q \in Q$ such that $\beta_{n-1}(q_{n-1}) = \true$. Then
  we have $\I,\beta\cup\bigcup_{i=0}^n\nu_i \models \phi_n$
  where $\beta(q) = \beta_n(q_n)$, for all $q \in Q$ and $\phi_n$ is
  obtained from $\phi_{n-1}$ by replacing each boolean variable $q$ by
  $\Delta(a,q)[\vec{x}_{n-1}/\overline{\vec{x}},\vec{x}_n/\vec{x}]$. Observe
  that, because each boolean variable occurs positively in
  $\phi_{n-1}$, the truth value of
  $\Delta(a,q)[\vec{x}_{n-1}/\overline{\vec{x}},\vec{x}_n/\vec{x}]$
  under the valuation $\beta\cup\nu_{n-1}\cup\nu_n$ is not important for
  any $q \in Q$ such that $\beta(q) = \false$. We have obtained a
  model for $\phi_n$ and thus for $\Post{\A}(u)$. Since moreover,
  $\theta_{n+1}[Q/Q_n] = \true$ in this model, we obtain a model for
  $\Accept{\A}(u)$. Thus $\pi(u)$ is satisfiable implies that
  $\Accept{\A}(u)$ is satisfiable, which proves the statement of point
  (\ref{it1:progress}).

  (\ref{it2:progress}) If $\tuple{\top,I_1,\dots,I_{n+1},\bot}$ is an
    interpolant for $\pi(u)$, the following entailments hold: \begin{compactitem}
    \item $\theta_0 \models I_1[Q_0/Q]$, 
      %
    \item $I_k[Q_{k-1}/Q,\vec{x}_{k-1}/\vec{x}] \wedge \theta_k \models I_{k+1}[Q_k/Q,\vec{x}_k/\vec{x}]$, $\forall k\in[1,n]$. 
      %
    \item $I_{n+1}[Q_{n+1}/Q] \wedge \theta_{n+1} \models \bot$. 
    \end{compactitem}
    We prove that $\AbsPost{\A}(\iota,a_1\ldots a_n) \models I_{n+1}$
    by induction on $n \geq 0$. This is sufficient to conclude because
    $\AbsAccept{\A}(a_1\ldots a_n) \equiv \AbsPost{\A}(\iota,a_1\ldots
    a_n) \wedge \theta_{n+1}[Q/Q_n] \models I_{n+1} \wedge
    \theta_{n+1}[Q/Q_n] \models \bot$. For the base case $n=0$, we
    have $\AbsPost{\A}(\iota,\varepsilon) \equiv \iota \equiv
    \theta_0[Q/Q_0] \models I_1$. For the induction step $n>0$, we
    compute:
    \[\begin{array}{l}
    \AbsPost{\A}(\iota,a_1\ldots a_n)[Q_n/Q] \equiv \text{ (by definition of $\AbsPost{\A}$)} \\
    \exists \vec{x}_{n-1} ~.~ \abs{\Delta^n(\AbsPost{\A}(\iota,a_1\ldots a_{n-1}),a_n)}[Q_n/Q] \models \text{ ($\Asterisk$)} \\
    \exists Q_{n-1}  \exists \vec{x}_{n-1} ~.~ \AbsPost{\A}(\iota,a_1\ldots a_{n-1})[Q_{n-1}/Q] \wedge \theta_n \models \text{ (ind. hyp.) } \\
    \exists Q_{n-1}  \exists \vec{x}_{n-1} ~.~ I_{n-1}[Q_{n-1}/Q] \wedge \theta_n \models I_n[Q_n/Q]  \hfill\text{\qed}
    \end{array}\]
   Let us prove the final point ($\Asterisk$). If
   $\I,\beta_n\cup\nu_{n-1}\cup\nu_n \models
   \abs{\Delta^n(\AbsPost{\A}(\iota,a_1\ldots a_{n-1}),a_n)}[Q_{n}/Q]$,
   for some valuations $\beta_{n} : Q_{n-1} \rightarrow \booli$ and
   $\nu_i : \vec{x}_i \rightarrow \Data^\I$, for $i=n-1,n$, then we
   build a valuation $\beta_{n-1}$ such that
   $\I,\beta_{n-1}\cup\beta_n \cup \nu_{n-1}\cup\nu_n \models
   \AbsPost{\A}(\iota,a_1\ldots a_{n-1})[Q_{n-1}/Q] \wedge \theta_n$,
   as follows. For each occurrence of a subformula $\Delta(q,a_n)$ in
   $\AbsPost{\A}(\iota,a_1\ldots a_{n-1})$ we set
   $\beta_{n-1}(q_{n-1}) = \true$ if $\I,\beta_n\cup\nu_{n-1}\cup\nu_n
   \models \Delta(q,a_n)[Q_n/Q]$ and $\beta_{n-1}(q_{n-1}) = \false$,
   otherwise. Since there are no negated occurrences of such
   subformulae, the definition of $\beta_{n-1}$ is consistent, and the
   check $\I,\beta_{n-1}\cup\beta_n \cup \nu_{n-1}\cup\nu_n \models
   \AbsPost{\A}(\iota,a_1\ldots a_{n-1})[Q_{n-1}/Q] \wedge \theta_n$
   is straightforward. \qed}

We have now all the ingredients to describe the first emptiness
checking semi-algorithm for alternating data
automata. Algorithm\footnote{Though termination is not guaranteed,
  we call it algorithm for conciseness.}  \ref{alg:predabs} builds
an \emph{abstract reachability tree} (ART) whose edges are labeled
with input events and each node $n$ is labeled with the formula
$\AbsPost{\A}(\iota,u)$, where $u \in \Sigma^*$ is the event trace
labeling the path from the root of the tree to $n$. It uses a covering
relation $\lhd$ between nodes in order to ensure that the set of
formulae labeling the nodes in the ART forms an antichain. Any
spurious counterexample $u$ is eliminated by computing the
interpolants corresponding to the least unfeasible suffix $v$ of $u$
and recomputing the subtree of the ART rooted in the initial node of
$v$.

\begin{algorithm}[t!]
{\scriptsize\begin{algorithmic}[0]
\State {\bf input}: an ADA $\A = \tuple{\vec{x},Q,\iota,F,\Delta}$
over the alphabet $\Sigma$ of input events

\State {\bf output}: $\true$ if $L(\A)=\emptyset$ and a data word $w
\in L(\A)$ otherwise
\end{algorithmic}}

{\scriptsize\begin{algorithmic}[1] 

  \State let $\Art = \tuple{N,E,\Lambda,\lhd}$ be an ART 

  \State initially $N = E = \lhd = \emptyset$, $\Lambda =
  \set{(\rootNode,\iota)}$, $\preds = \set{\bot}$, $\worklist =
  \tuple{\rootNode}$,

  \While {$\worklist \neq \emptyset$}
  \label{ln:while}
  
  \State dequeue $n$ from $\worklist$ 

  \State $N \leftarrow N \cup \set{n}$

  \If{$\Lambda(n) \wedge \bigwedge_{q \in Q \setminus F} (q
    \rightarrow \bot)$ is satisfiable} \Comment{counterexample candidate}

  \State let $u = a_1\ldots a_k$ be the label of the path from
  $\rootNode$ to $n$ in $\Art$

  \If{$\Accept{\A}(u)$ is satisfiable} \Comment{counterexample is
    real}

  \State get model $\beta : Q \rightarrow \booli$, $\{\nu_i :
  \vec{x}_i \rightarrow \Data^\I \mid i=0\ldots k\}$ of $\Accept{\A}(u)$

  \State {\bf return} $w = (a_1,\nu_1) \ldots (a_k,\nu_k)$
  \label{ln:cex}
  \Comment{$w \in L(\A)$ by construction}

  \Else \Comment{spurious counterexample}

  \State $p \leftarrow \Call{FindPivot}{u,\Art}$
  \label{ln:pivot}

  \State let $v$ be the label of the path from $p$ to $n$ in $\Art$
  
  \State $\preds \leftarrow \preds \cup \set{I_1,\ldots,I_\ell}$,
  where $\tuple{\top,I_1,\ldots,I_\ell,\bot}$ is an interpolant for
  $\overline{\pi}(v)$

  \State let $\SubArt = \tuple{N',E',\Lambda',\lhd'}$ be the subtree
  rooted at $p$ in $\Art$

  \For{$(m,q) \in \lhd$ such that $q \in N'$}

  \State remove $m$ from $N$ and enqueue $m$ into $\worklist$

  \State remove $\SubArt$ from $\Art$

  \State enqueue $p$ into $\worklist$
  \label{ln:refine}
  \Comment{recompute the subtree rooted at $p$}

  \EndFor

  \EndIf

  \Else \label{ln:else}

  \For{$a \in \Sigma$}\label{ln:forall-events}
  \Comment{expand $n$}

  \State $\phi \leftarrow \AbsPost{\A}(\Lambda(n),a)$

  \If{exist $m \in N$ such that $\phi \models \Lambda(m)$} \label{ln:covered}

  \State $\lhd \leftarrow \lhd \cup \set{(n,m)}$ \Comment{$m$ covers $n$}
  \label{ln:direct-cover}

  \Else 

  \State let $s$ be a fresh node

  \State $E \leftarrow E \cup \set{(n,a,s)}$

  \State $\Lambda \leftarrow \Lambda \cup \set{(s,\phi)}$

  \State $R \leftarrow \set{m \in \worklist \mid \Lambda(m) \models
    \phi}$ \Comment{worklist nodes covered by $s$}

  \For{$r \in R$}
  
  \For{$m \in N$ such that $(m,b,r) \in E$, $b \in \Sigma$}

  \State $\lhd \leftarrow \lhd \cup \set{(m,s)}$ 
  \label{ln:child-cover}
  \Comment{redirect covered children from $R$ into $s$}

  \EndFor

  \For{$(m,r) \in \lhd$}

  \State $\lhd \leftarrow \lhd \cup \set{(m,s)}$ 
  \label{ln:indirect-cover}
  \Comment{redirect covered nodes from $R$ into $s$}

  \EndFor

  \EndFor

  \State remove $R$ from $\Art$

  \State enqueue $s$ into $\worklist$ 
  \label{ln:expand}

  \EndIf

  \EndFor

  \EndIf

  \EndWhile

  \State {\bf return} $\true$
  \label{ln:true}
\end{algorithmic}}
\caption{Lazy Predicate Abstraction for ADA Emptiness}
\label{alg:predabs}
\end{algorithm}

Formally, an ART $\Art = \tuple{N,E,\Lambda,\lhd}$ is a tree, where
$N$ is a set of nodes, $E \subseteq N \times \Sigma \times N$ is a set
of edges, $\Lambda : N \rightarrow \Form^+(Q,\vec{x})$ is a labeling
of the nodes with formulae and $\lhd \subseteq N \times N$ is a set of
covering edges. We require that $(N,E)$ is a directed tree, rooted at
$\rootNode \in N$, where $\Lambda(\rootNode) = \iota$. Then each node
$n \in N$ corresponds to a unique path from the root to $n$, labeled
by a sequence $u$ of input events. The least unfeasible suffix of $u$
is the smallest sequence $v = a_1 \ldots a_k$, such that $u = wv$, for
some $w \in \Sigma^*$ and the formula (\ref{eq:pivot}) below is
unsatisfiable. The \emph{pivot} of $u$ is the node $p$ corresponding
to the start of $v$ in $u$.
\begin{equation}\label{eq:pivot}
  \overline{\pi}(v) \equiv \Lambda(p)[Q_0/Q] \wedge
  \theta_1(Q_0 \cup Q_1,\vec{x}_0 \cup \vec{x}_1) \wedge \ldots \wedge
  \theta_{k+1}(Q_k)
\end{equation}
where $\theta_1,\ldots,\theta_{k+1}$ are defined as in
(\ref{eq:interpolation-problem}), for $\theta_0 \equiv
\Lambda(p)[Q_0/Q]$. 

With these considerations, Algorithm \ref{alg:predabs} uses a worklist
iteration to build an ART. We keep newly expanded nodes of $\Art$ in a
use a queue $\worklist$ to ensure a breadth-first exploration
strategy, which guarantees that the shortest counterexamples are
explored first. When the search encounters a counterexample $u$, it is
checked for spuriousness. If the counterexample is real, the procedure
returns a data word $w \in L(\A)$, which interleaves the input events
of $u$ with the data valuations from the model of $\Accept{\A}(u)$
(since $u$ is feasible, clearly $\Accept{\A}(u)$ is
satisfiable). Otherwise, if $u$ is spurious, we compute its pivot $p$
(line \ref{ln:pivot}), add the interpolants for the least unfeasible
suffix of $u$ to the set of predicates $\preds$, remove and recompute
the subtree of $\Art$ rooted at $p$.

Termination of Algorithm \ref{alg:predabs} depends on the ability of a
given interpolating decision procedure for the combined boolean and
data theory $\theory(\sig,\I)$ to provide interpolants that yield a
safety invariant, provided that $L(\A) = \emptyset$. In this case, we
use the covering relation $\lhd$ to ensure that, when a newly
generated node is covered by a node already in $N$, it is not added to
the worklist, thus cutting the current branch of the search. Formally,
for any two nodes $n,m \in N$, we have $n \lhd m$ iff
$\AbsPost{\A}(\Lambda(n),a) \models \Lambda(m)$ for some $a \in
\Sigma$, in other words, if $n$ has a successor whose label entails
the label of $m$. The correctness criteria of Algorithm
\ref{alg:predabs} are showed in the following theorem:

\begin{theorem}\label{thm:predabs}
  Given an automaton $\A$, such that $L(\A) \neq \emptyset$, Algorithm
  \ref{alg:predabs} terminates and returns a word $w \in L(\A)$. If
  Algorithm \ref{alg:predabs} terminates reporting $\true$, then
  $L(\A) = \emptyset$.
\end{theorem}
\proof{To prove the first point, assume w.l.o.g. that $\Sigma =
  \set{a_1,\ldots,a_{\card{\Sigma}}}$ is a total ordering of the input event
  alphabet of $\A$ and that the loop at line \ref{ln:forall-events}
  considers the events in this order. If $L(\A) \neq \emptyset$, let
  $(a_{i_1},\nu_1) \ldots (a_{i_k},\nu_k) \in L(\A)$ be a word, such
  that $a_{i_1} \ldots a_{i_k}$ is the lexicographically minimal
  feasible counterexample for $\A$.  Since Algorithm \ref{alg:predabs}
  explores $\Sigma^*$ in this lexicographical order, it must encounter
  $a_{i_1} \ldots a_{i_k}$ and return a word $(a_{i_1},\nu'_1) \ldots
  (a_{i_k},\nu'_k) \in L(\A)$ at line \ref{ln:cex}.

  For the second point, we prove the following invariant: each time
  Algorithm \ref{alg:predabs} reaches line \ref{ln:while}, the set $W$
  of nodes in $\worklist$ contains all the frontier nodes in $\Art =
  \tuple{N,E,\Lambda,\lhd}$ which are not covered by some node in $N$,
  namely that $W = \set{n \in N \mid \forall m \in N \forall a \in
    \Sigma ~.~ (n,a,m) \not\in E ~\wedge~ (n,m) \not\in
    \lhd}$. Initially, this is the case because $W = \set{\rootNode}$
  and $E = \lhd = \emptyset$. If the invariant holds previously, at
  line \ref{ln:while}, it will hold again after line \ref{ln:refine}
  is executed, because, when the subtree rooted at the pivot $p$ is
  removed, $p$ becomes a member of the set of uncovered frontier
  nodes, and is added to $W$ at line \ref{ln:refine}. The last case
  considers that the invariant holds at line \ref{ln:while} and the
  control follows the else branch at line \ref{ln:else}. In this case,
  the newly created frontier node $s$ is added to $W$ only if it is
  not covered by an existing node in $N$ (line \ref{ln:covered}). 

  We use this invariant in the proof as follows. If Algorithm
  \ref{alg:predabs} returns at line \ref{ln:true}, then it must be
  that $W = \emptyset$. Because of the invariant, each node in $N$ is
  either covered by another node in $N$, or all its successors are in
  $N$. We prove next that $\bigvee_{n \in N} \Lambda(n)$ defines a
  safety invariant, which allows to conclude that $L(\A) = \emptyset$,
  by Lemma \ref{lemma:safety-invariant}. To this end, it is sufficient
  to prove that, for any $u \in \Sigma^*$, there exists some node $n
  \in N$ such that $\Post{\A}(\iota,u) \models \Lambda(n)$. Let $u \in
  \Sigma^*$ be an arbitrary sequence. If $u$ labels the path from
  $\rootNode$ to some $n \in N$, we have $\Post{\A}(\iota,u) \models
  \AbsPost{\A}(\iota,u) \models \Lambda(n)$ and we are
  done. Otherwise, let $v$ be the (possibly empty) prefix of $u$ which
  labels the path from $\rootNode$ to some $n \in N$, which is covered
  by another $m \in N$, where $(n,a,m) \in E$, that is $u = vav'$, for
  some $a \in \Sigma$ and $v'\in\Sigma^*$. Moreover, we have
  $\Post{\A}(\iota,va) \models \AbsPost{\A}(\iota,va) \models
  \Lambda(m)$, by the construction of the set $\lhd$ of covering edges
  --- lines \ref{ln:direct-cover}, \ref{ln:child-cover},
  \ref{ln:indirect-cover}. Continuing this argument recursively from
  $m$, since $\len{v'} < \len{u}$, we shall eventually discover a node
  $p$ such that $\Post{\A}(\iota,u) \models \Lambda(p)$. This
  concludes the proof. \qed}

\section{Checking ADA Emptiness with \impact}

As pointed out by a number of authors (e.g.\ \cite{mcmillan06}) the
bottleneck of predicate abstraction is the high cost of existential
quantifier elimination required to compute the $\Post{\A}(\phi,a)$
function --- we recall that $\Post{\A}(\phi,a)$ is defined by the
formula $\overline{\vec{x}} ~.~
\Delta(\phi[\overline{\vec{x}}/\vec{x}],a)$. The main idea of the
\impact~ procedure is that interpolation can be used instead
quantifier elimination, because an interpolant over-approximates the
post-images along the counterexample path in a way that is sufficient
to prove its spuriousness.

With this in mind, Algorithm \ref{alg:impact} builds an ART for the
given automaton and uses interpolants, instead of abstract
post-images, to label its nodes. To speedup the computation we use two
additional labeling functions for bookkeeping. Formally, the ART
structure used by Algorithm \ref{alg:impact} is defined as $\Art =
\tuple{N,E,\Lambda,R,T,\lhd}$, where $N,E,\Lambda$ and $\lhd$ are
defined as for Algorithm \ref{alg:predabs} and,
moreover: \begin{compactitem}
\item $R : N \rightarrow 2^Q$ is a labeling of nodes with replacement
  sets, such that $R(\rootNode) = \fv{\Bool}{\iota}$, 
%
\item $T : E \rightarrow \bigcup_{i=0}^\infty
  \Form(Q_i,\vec{x}_i,Q_{i+1},\vec{x}_{i+1})$ is labeling of edges
  with time-stamped formulae, in which $Q_i$ may occur under negation,
  and
%
\item for each edge $e = (n,a,m) \in E$, if $n$ lies at
  depth\footnote{We consider that the root node has zero depth.}
  $k\geq0$ in the tree $(N,E)$, then we have:
  \[\begin{array}{rcl}
  T(e) & = & \Theta(n,k) \\
  R(m) & = & \bigcup_{q \in R(n)}\fv{\Bool}{\Delta(q,a)} \text{ where} \\
  \Theta(n,k) & \equiv & \bigwedge_{q \in R(n)} (q_k \rightarrow
  \Delta(q,a)[Q_{k+1}/Q,\vec{x}_{k}/\overline{\vec{x}},\vec{x}_{k+1}/\vec{x}])
  \end{array}\]
\end{compactitem}
For simplicity, we write $T(n,a,m)$ for $T(e)$, when $e$ is
$(n,a,m)$. The idea behind this additional bookkeeping is that, given
a sequence $u = a_1\ldots a_k \in \Sigma^*$ that labels the path
from the root to a node $n$ in $\Art$, the conjunction: 
\[\mu(n) \equiv \Lambda(\rootNode) \wedge T(\rootNode,a_1,n_1) \wedge \ldots
T(n_{k-1},a_k,n_k) \wedge \bigwedge_{q \in R(n_k) \setminus F}(q
\rightarrow \bot)\] is equivalent to the interpolation problem
$\pi(u)$. We assume furthermore a total alphabetical order $\prec$ on
$\Sigma$ and lift it to the total lexicographical order $\prec^*$ on
$\Sigma^*$. We write $n \prec^* m$ if the sequence labeling the path
from $\rootNode$ to $n$ is strictly smaller, in the lexicographical
order, than the sequence labeling the path from $\rootNode$ to $m$. A
node $n \in N$ is \emph{covered by $m$} if $(n,m) \in \lhd$ and simply
covered when $m$ is not important. A node $n$ is \emph{closed} if for
all nodes $m \in N$ such that $m \prec^* n$, either $\Lambda(n)
\not\models \Lambda(m)$ or $(n,m) \in \lhd$.

\begin{algorithm}[t!]
{\scriptsize\begin{algorithmic}[0]
  \State {\bf input}: an ADA $\A = \tuple{\vec{x},Q,\iota,F,\Delta}$
  over the alphabet $\Sigma$ of input events

  \State {\bf output}: $\true$ if $L(\A)=\emptyset$ and a data word $w
  \in L(\A)$ otherwise
\end{algorithmic}}

{\scriptsize\begin{algorithmic}[1] 

  \State let $\Art = \tuple{N,E,\Lambda,R,T,\lhd}$ be an ART 

  \State initially $N = E = T = \lhd = \emptyset$, $\Lambda =
  \set{(\rootNode,\iota)}$, $R = \fv{\Bool}{\iota[Q_0/Q]}$,
  $\worklist=\set{\rootNode}$
  
  \While{$\worklist \neq \emptyset$}

  \State dequeue $n$ from $\worklist$ 

  \State $N \leftarrow N \cup \set{n}$

  \For{$m \in N$ such that $m \prec^* n$}
  \Comment{close $n$} 

  \If{$\Lambda(n) \models \Lambda(m)$}

  \State $\lhd \leftarrow \lhd \setminus \set{ (p,q) \in \lhd \mid
    \text{$q$ is a successor of $n$}}$

  \State $\lhd \leftarrow \lhd \cup \set{(n,m)}$

  \EndIf

  \EndFor

  \If{$n$ is not covered}

  \If{$R(n) \cap F \neq \emptyset$} 
  \Comment{counterexample candidate}

  \If{$\mu(n)$ is satisfiable} 
  \Comment{counterexample is real}

  \State get model $\beta : Q_i \rightarrow \booli$, $\{\nu_i :
  \vec{x}_i \rightarrow \Data^\I \mid i=0\ldots k\}$ of $\mu(n)$

  \State {\bf return} $w = (a_1,\nu_1) \ldots (a_k,\nu_k)$
  \Comment{$w \in L(\A)$ by construction}

  \Else \Comment{spurious counterexample}

  \State let $\rootNode,n_1,\ldots,n_k,n$ be the sequence of nodes from $\rootNode$ to $n$

  \State let $\tuple{\top,I_1,\ldots,I_k,I_{k+1}\equiv\bot}$ be an interpolant for $\mu(n)$

  \For{$i=1,\ldots,k+1$}

  \If{$\Lambda(n_i) \not\models I_i$}

  \State $\lhd \leftarrow \lhd \setminus \set{(m,n_i) \in \lhd \mid m \in N}$
  \Comment{uncover $n_i$}

  \State $\Lambda(n_i) \leftarrow \Lambda(n_i) \wedge I_i$
  \Comment{strenghten the label of $n_i$}

  \EndIf

  \EndFor

  \EndIf

  \For{$a \in \Sigma$} 
  \Comment{expand $n$}
  
  \State let $s$ be a fresh node and $e \leftarrow (n,a,s)$

  \State $E \leftarrow E \cup \set{e}$

  \State $\Lambda \leftarrow \Lambda \cup \set{(s,\top)}$

  \State $T \leftarrow T \cup \set{(e, \Theta(n,k))}$

  \State $R \leftarrow R \cup \{(s,\bigcup_{q \in R(n)}\fv{\Bool}{\Delta(q,a)})\}$

  \State enqueue $s$ into $\worklist$

  \EndFor

  \EndIf

  \EndIf

  \EndWhile  
\end{algorithmic}}
\caption{\impact~ for ADA Emptiness}
\label{alg:impact}
\end{algorithm}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\bibliographystyle{abbrv} \bibliography{refs}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\end{document}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
