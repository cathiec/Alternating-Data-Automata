\documentclass{llncs}

\usepackage[usenames,dvipsnames]{color}

\usepackage{latexsym}
\usepackage{amsxtra} 
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{pslatex}
\usepackage{epsfig}
\usepackage{wrapfig}
\usepackage{paralist}
\usepackage{graphics}
\usepackage{stmaryrd}
\usepackage{txfonts}
\usepackage{framed}
\usepackage{makecell}
\usepackage{url}
\usepackage{tikz}
\usetikzlibrary{automata,positioning, calc}
\usepackage[inline,shortlabels]{enumitem}

\usepackage{proof}

\usepackage{algorithm}
\usepackage{algorithmicx}
\usepackage[noend]{algpseudocode}

\usepackage[draft]{commenting}

\pagestyle{plain}

\include{commands}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\title{The Impact of Alternation}

\author{Radu Iosif \and Xiao Xu}

\institute{Verimag/CNRS/Universit\'e de Grenoble Alpes}

\maketitle

\begin{abstract}
\end{abstract}

\section{Introduction}

\section{Preliminaries}

A \emph{signature} $\sig = (\ssorts{\sig},\sfuns{\sig})$ consists of a
set $\ssorts{\sig}$ of \emph{sort symbols} and a set $\sfuns{\sig}$ of
sorted \emph{function symbols}. To simplify the presentation, we
assume w.l.o.g. that $\ssorts{\sig}$ consists of two distinct sorts
$\Data$ and $\Bool$ and each function symbol $f \in \sfuns{\sig}$ has
$\#(f) \geq 0$ arguments of sort $\Data$ and return value $\sigma(f)
\in \ssorts{\sig}$. If $\#(f)=0$ then $f$ is a \emph{constant}. We
consider the constants $\mathbf{0}$ of sort $\Data$ and $\top,\bot$ of
sort $\Bool$.

We consider an infinite countable set of \emph{variables} $\vars$,
where each $x \in \vars$ has an associated sort $\sigma(x)$. Terms are
defined recursively: a term $t$ of sort $\sigma(t)=S$ is a variable $x
\in \vars$ where $\sigma(x)=S$, or $f(t_1,\ldots,t_{\#(f)})$ where
$t_1,\ldots,t_{\#(f)}$ are terms of sort $\Data$ and $\sigma(f)=S$. An
\emph{atom} is a term of sort $\Bool$ or an equality $t \teq s$
between two terms of sort $\Data$. A \emph{literal} is an atom or its
negation. A \emph{formula} is an existentially quantified combination
of atoms using disjunction $\vee$, conjunction $\wedge$ and negation
$\neg$ and we write $\phi \rightarrow \psi$ for $\neg\phi \vee \psi$.

We denote by $\fv{S}{\phi}$ the set of free (i.e.\ not under the scope
of an existential quantifier) variables of sort $S$ in $\phi$ and
write $\fv{}{\phi}$ for $\bigcup_{S \in \set{\Data,\Bool}}
\fv{S}{\phi}$. For a variable $x \in \fv{}{\phi}$ and a term $t$ such
that $\sigma(t) = \sigma(x)$, let $\phi[t/x]$ be the result of
replacing each occurrence of $x$ by $t$. For indexed sets
$\vec{t}=\set{t_1,\ldots,t_n}$ and $\vec{x}=\set{x_1,\ldots,x_n}$, we
write $\phi[\vec{t}/\vec{x}]$ for the formula obtained by
simultaneously replacing $x_i$ with $t_i$ in $\phi$, for all
$i=1,\ldots,n$.
%
%% A formula is in positive normal form (PNF) if negation occurs only
%% within literals and in disjunctive normal form (DNF) if it is a
%% disjunction of conjunctions of literals $\bigvee_{i=1}^N
%% \bigwedge_{j=1}^{M_i} \ell_{ij}$.
%
The size of a formula $\phi$, denoted $\len{\phi}$ is the number of
symbols occuring in it.

An \emph{interpretation} $\I$ maps\begin{inparaenum}[(1)]
\item the sort $\Data$ into a non-empty set $\Data^\I$, 
%
\item the sort $\Bool$ into the set $\booli = \set{\true,\false}$, where
  $\top^\I = \true$, $\bot^\I = \false$, and
%
\item each function symbol $f$ into a total function $f^\I :
  (\Data^\I)^{\#(f)} \rightarrow \sigma(f)^I$, or an element of
  $\sigma(f)^I$ when $\#(f)=0$.
\end{inparaenum}
Given an interpretation $\I$, a \emph{valuation} $\nu$ maps each
variable $x \in \vars$ into an element $\nu(x) \in \sigma(x)^\I$. For
a term $t$, we denote by $t^\I_\nu$ the value obtained by replacing
each function symbol $f$ by its interpretation $f^\I$ and each
variable $x$ by its valuation $\nu(x)$. For a formula $\phi$, we write
$\I,\nu \models \phi$ if the formula obtained by replacing each term
$t$ in $\phi$ by the value $t^\I_\nu$ is logically equivalent to true.
A formula $\phi$ is \emph{satisfiable} in the interpretation $\I$ if
there exists a valuation $\nu$ such that $\I,\nu \models \phi$. The
\emph{theory} $\theory(\sig,\I)$ is the set of satisfiable formulae
written in the signature $\sig$, with the interpretation $\I$. 

Given formulae $\varphi$ and $\psi$, we say that \emph{$\phi$ entails
  $\psi$}, denoted $\phi \models^\I \psi$ iff $\I,\nu \models \varphi$
implies $\I,\nu \models \psi$, for each valuation $\nu$, and $\phi
\eqiff^\I \psi$ iff $\phi \models^\I \psi$ and $\psi \models^\I \phi$.
We omit mentioning the interpretation $\I$ when it is clear from the
context.

\section{Alternating Data Automata}

In the rest of this section we fix an interpretation $\I$ and a finite
alphabet $\Sigma$ of \emph{input events}. Given a finite set $\vec{x}
\subset \vars$ of variables of sort $\Data$, let $\vec{x} \mapsto
\Data^\I$ be the set of valuations of the variables $\vec{x}$ and
$\Sigma[\vec{x}] = \Sigma \times (\vec{x} \mapsto \Data^\I)$ be the
set of \emph{data symbols}. A \emph{data word} (or, simply, a word) is
a finite sequence $(a_1,\nu_1)(a_2,\nu_2) \ldots (a_n,\nu_n)$ of data
symbols, where $a_1,\ldots,a_n \in \Sigma$ and $\nu_1,\ldots,\nu_n :
\vec{x} \rightarrow \Data^\I$ are valuations. We denote by
$\varepsilon$ the empty sequence, by $\Sigma^*$ the set of finite
sequences of input events and by $\Sigma[\vec{x}]^*$ the set of data
words over $\vec{x}$.

This definition generalizes the classical notion of words from a
finite alphabet to using a possibly infinite alphabet
$\Sigma[\vec{x}]$. Clearly, when $\Data^\I$ is sufficiently large or
infinite, we can map the elements of $\Sigma$ into designated elements
of $\Data^\I$ and use a special variable to encode the input
events. However, keeping $\Sigma$ explicit in the following simplifies
several technical points below, without cluttering the presentation.

Given sets of variables $\vec{b},\vec{x} \subset \vars$ of sort
$\Bool$ and $\Data$, respectively, we denote by
$\Form^+(\vec{b},\vec{x})$ the set of formulae $\phi$ such that
$\fv{\Bool}{\phi} \subseteq \vec{b}$, $\fv{\Data}{\phi} \subseteq
\vec{x}$ and each variable from $\vec{b}$ occurs under an even number
of negations. 

An \emph{alternating data automaton} (or, simply, and automaton) is a
tuple $\A = \tuple{\vec{x},Q,\iota,F,\Delta}$: \begin{compactitem}
%
\item $\vec{x} \subset \vars$ is a finite set of variables of sort
  $\Data$,
%
\item $Q$ is a finite set of variables of sort $\Bool$, also called
  \emph{states},
%
\item $\iota \in \Form^+(Q,\emptyset)$ is a formula describing the
  \emph{initial configurations},
%
\item $F \subseteq Q$ is a set of \emph{final} states, and
%
\item $\Delta : Q \times \Sigma \rightarrow
  \Form^+(Q,\overline{\vec{x}}\cup\vec{x})$ is a \emph{transition
    function}, where $\overline{\vec{x}}$ is the set $\{\overline{x}
  \mid x \in \vec{x}\}$.
\end{compactitem}
Intuitively, in each formula describing a transition rule,
$\overline{\vec{x}}$ track the previous and $\vec{x}$ the current
values of the variables of $\A$. Observe further, that the initial
values of the variables are left unconstrained, because the initial
configuration does not contain free data variables. The size of $\A$
is defined as $\len{\A} = \len{\iota} + \sum_{(q,a) \in
  Q\times\Sigma}\len{\Delta(q,a)}$.

Formally, let $\vec{x}_k = \set{x_k \mid x \in \vec{x}}$, $k\geq0$, be
a time-stamped set of variables. For an input even $a \in \Sigma$ and
a formula $\phi$ we write $\Delta^k(\phi,a)$ for the formula obtained
from $\phi$ by simultaneously replacing each state $q \in
\fv{\Bool}{\phi}$ by the formula
$\Delta(q,a)[\vec{x}_k/\overline{\vec{x}},\vec{x}_{k+1}/\vec{x}]$, for
all $k\geq0$. Given a word $w = (a_1,\nu_1)(a_2,\nu_2) \ldots
(a_n,\nu_n)$, the \emph{run} of $\A$ over $w$ is the sequence of
formulae $\phi_0,\phi_1,\ldots,\phi_n$, where $\phi_0 \equiv \iota$
and, for all $k > 0$, we have $\phi_k \equiv
\Delta^k(\phi_{k-1},a_k)$. We slightly abuse notation and write
$\Delta(\iota,a_1,\ldots,a_n)$ for the formula
$\phi_n(\vec{x}_0,\ldots,\vec{x}_n)$ in the following. We say that
$\A$ \emph{accepts} $w$ iff $\I,\nu \models \phi_n$, where $\nu$ is
some valuation that maps:\begin{inparaenum}[(1)]
%
\item each $x \in \vec{x}_k$ to $\nu_k(x)$, for all $k\in[1,n]$, 
%
\item each $q \in \fv{\Bool}{\phi_n} \cap F$ to $\top$, and 
%
\item each $q \in \fv{\Bool}{\phi_n} \setminus F$ to $\bot$.
\end{inparaenum}
The language of $\A$ is the set $L(\A)$ of words accepted by $\A$.

In this section we tackle the following problems: \begin{compactenum}
\item \emph{boolean closure}: given automata $\A_1$ and $\A_2$, both
  with the same set of variables $\vec{x}$, do there exist automata
  $\A_\cup$, $\A_\cap$ and $\overline{\A}$ such that $L(\A_\cup) =
  \A_1 \cup \A_2$, $L(A_\cap) = \A_1 \cap \A_2$ and
  $L(\overline{\A_1}) = \Sigma[\vec{x}]^* \setminus L(\A_1)$ ?
%
\item \emph{emptiness}: given an automaton $\A$, is it the case that
  $L(\A) = \emptyset$ ?
\end{compactenum}

It is well known that other problems, such as \emph{universality}
(given an automaton $\A$ with variables $\vec{x}$, does $L(\A) =
\Sigma[\vec{x}]^*$) and \emph{inclusion} (given automata $\A_1$ and
$\A_2$ with the same set of variables, does $L(\A_1) \subseteq
L(\A_2)$ ?) can be reduced to the above problems. Observe furthermore
that we do not consider cases in which the sets of variables in the
two automata differ. An interesting problem in this case is: given
automata $\A_1$ and $\A_2$, with variables $\vec{x}_1$ and
$\vec{x}_2$, respectively, such that $\vec{x}_1 \subseteq \vec{x}_2$,
does $L(\A_1) \subseteq \proj{L(\A_2)}{\vec{x}_1}$, where
$\proj{L(\A_2)}{\vec{x}_1}$ is the projection of the set of words
$L(\A_2)$ onto the variables $\vec{x}_1$? This problem is considered
as future work.

\subsection{Boolean Closure}

Given a set $Q$ of boolean variables and a set $\vec{x}$ of variables
of sort $\Data$, for a formula $\phi \in \Form^+(Q,\vec{x})$, with no
negated occurrences of the boolean variables, we define the formula
$\overline{\phi} \in \Form^+(Q,\vec{x})$ recursively on the structure
of $\phi$:
\[\begin{array}{lclclclclcl}
\overline{\phi_1 \vee \phi_2} & \equiv & \overline{\phi_1} \wedge \overline{\phi_2} && 
\overline{\phi_1 \wedge \phi_2} & \equiv & \overline{\phi_1} \vee \overline{\phi_2} && 
\overline{\neg\phi} & \equiv & \neg \overline{\phi} \text{ if $\phi$ is not an atom} \\
\overline{\phi} & \equiv & \phi \text{  if $\phi \in Q$}\hspace*{1cm} &&
\overline{\phi} & \equiv & \neg\phi \text{  if $\phi \not\in Q$ is an atom}
\end{array}\]
It is easy to check that $\len{\overline{\phi}} = \len{\phi}$, for
every formula $\phi \in \Form^+(Q,\vec{x})$. If $\phi$ does not
contain boolean variables, then $\overline{\phi}$ and $\neg\phi$ are
equivalent, and in general:

\begin{proposition}\label{prop:overline}
  Given a formula $\phi \in \Form^+(Q,\vec{x})$ and a valuation $\nu$
  mapping each $q \in Q$ a value $\nu(q) \in \booli$ and each $x \in
  \vec{x}$ to a value $\nu(x) \in \Data^\I$, let $\nu'$ be the
  valuation that assigns each $q \in Q$ the value $\neg\nu(q)$ and
  each $x \in \vec{x}$ the value $\nu(x)$. Then we have 
  $\I,\nu \models \phi \iff \I,\nu' \not\models \overline{\phi}$. 
\end{proposition}
\proof{Immediate, by induction on the structure of $\phi$. \qed}

In the following let $\A_1 = \tuple{\vec{x},Q_1,\iota_1,F_1,\Delta_1}$
and $\A_2 = \tuple{\vec{x},Q_2,\iota_2,F_2,\Delta_2}$, where
w.l.o.g. we assume that $Q_1 \cap Q_2 = \emptyset$. We define $\A_\cup
= \tuple{\vec{x},Q_1\cup Q_2,\iota_1 \vee \iota_2,F_1\cup
  F_2,\Delta_1\cup\Delta_2}$, $\A_\cap = \tuple{\vec{x},Q_1\cup
  Q_2,\iota_1 \wedge \iota_2, F_1\cup F_2, \Delta_1\cup\Delta_2}$ and
$\overline{\A_1} = \langle \vec{x},Q_1,\iota_1,Q_1\setminus
F_1,\overline{\Delta_1} \rangle$, where $\overline{\Delta_1}(q,a)
\equiv \overline{\Delta_1(q,a)}$, for all $q \in Q_1$ and $a \in
\Sigma$. The following lemma shows the correctness of these
definitions: 

\begin{lemma}\label{lemma:closure}
  For any automata $\A_1 = \tuple{\vec{x},Q_1,\iota_1,F_1,\Delta_1}$
  and $\A_2 = \tuple{\vec{x},Q_2,\iota_2,F_2,\Delta_2}$ such that $Q_1
  \cap Q_2 = \emptyset$, we have $L(\A_\cup) = L(\A_1) \cup L(\A_2)$,
  $L(\A_\cap) = L(\A_1) \cap L(\A_2)$ and $L(\overline{\A_1}) =
  \Sigma[\vec{x}]^* \setminus L(\A_1)$.
\end{lemma}
\proof{ We prove $L(\A_\cup) = L(\A_1) \cup L(\A_2)$ first, the proof
  for $\A_\cap$ being analogous. Let $w = (a_1,\nu_1) \ldots
  (a_n,\nu_n)$ be a word, where $n=0$ corresponds to the empty
  word. We prove by induction on $n\geq0$ that $\Delta(\iota_1 \vee
  \iota_2,a_1\ldots a_n) \eqiff \Delta(\iota_1,a_1\ldots a_n) \vee
  \Delta(\iota_2,a_1\ldots a_n)$. The case $n=0$ follows from the
  definition of the initial configuration of $\A_\cup$. For the
  inductive step $n>0$, $\Delta(\iota_1 \vee \iota_2,a_1\ldots a_n)$
  is obtained from $\Delta(\iota_1 \vee \iota_2,a_1\ldots a_{n-1})$ by
  replacing each variable $q \in \fv{\Bool}{\Delta(\iota_1 \vee
    \iota_2,a_1\ldots a_{n-1})}$ with
  $\Delta(q,a_n)[\vec{x}_{n-1}/\overline{\vec{x}},\vec{x}_n/\vec{x}]$,
  denoted $\Delta^n(\Delta(\iota_1 \vee \iota_2,a_1\ldots
  a_{n-1}),a_n)$. Since by induction hypothesis, $\Delta(\iota_1 \vee
  \iota_2,a_1\ldots a_{n-1}) \eqiff \Delta(\iota_1,a_1\ldots a_{n-1})
  \vee \Delta(\iota_2,a_1\ldots a_{n-1})$, we obtain:
  \[\begin{array}{rcl}
  \Delta^n(\Delta(\iota_1 \vee \iota_2,a_1\ldots a_{n-1}),a_n) & \iff & 
  \Delta^n(\Delta(\iota_1,a_1\ldots a_{n-1}),a_n) \vee
  \Delta^n(\Delta(\iota_2,a_1\ldots a_{n-1}),a_n) \\
  & \iff & \Delta(\iota_1,a_1\ldots a_{n}) \vee \Delta(\iota_2,a_1\ldots
  a_{n}) \enspace.
  \end{array}\] 
  To prove $L(\overline{\A_1}) = \Sigma[\vec{x}]^* \setminus L(\A_1)$,
  let $w = (a_1,\nu_1) \ldots (a_n,\nu_n)$ be a word and show that
  $\overline{\Delta}(\iota_1,a_1 \ldots a_n) =
  \overline{\Delta(\iota_1,a_1 \ldots a_n)}$ by induction on
  $n\geq0$. The case $n=0$ is immediate, because $\fv{}{\iota_1}
  \subseteq Q$ and thus $\overline{\iota_1} = \iota_1$. For the case
  $n>0$, we compute:
  \[\begin{array}{rcll}
  \overline{\Delta}^n(\overline{\Delta}(\iota_1,a_1\ldots a_{n-1}),a_n) & \eqiff & 
  \overline{\Delta}^n(\overline{\Delta(\iota_1,a_1\ldots a_{n-1})},a_n) & \text{ by induction hypothesis} \\
  & \eqiff & \overline{\Delta(\iota_1,a_1\ldots,a_n)} & \text{ by the definition of $\overline{\phi}$ .}
  \end{array}\]
  Let $\nu,\nu' : (Q \cup \bigcup_{i=0}^n\vec{x}_i) \rightarrow (\booli
  \cup \Data^\I)$ be two valuations such that: \begin{compactitem}
  \item $\nu(q) = \top$ and $\nu'(q) = \bot$, for each $q \in F$, 
    %
  \item $\nu(q) = \bot$ and $\nu'(q) = \top$, for each $q \in Q \setminus F$, 
    %
  \item $\nu(x) = \nu'(x)$, for each $x \in \vec{x}_0$, 
    %
  \item $\nu(x) = \nu'(x) = \nu_i(x)$, for each $x \in \vec{x}_i$ and each $i
    \in [1,n]$.
  \end{compactitem}
  By Proposition \ref{prop:overline}, we have $\I,\nu \models
  \Delta(\iota_1,a_1 \ldots a_n) \iff \I,\nu' \not\models
  \overline{\Delta(\iota_1,a_1 \ldots a_n)} \iff \I,\nu' \not\models
  \overline{\Delta}(\iota_1,a_1 \ldots a_n)$. Thus $w \in L(\A_1) \iff
  w \not\in L(\overline{\A_1})$, i.e. $L(\overline{\A_1}) =
  \Sigma[\vec{x}]^* \setminus L(\A_1)$. \qed}

It is easy to see that $\len{\A_\cup} = \len{\A_\cap} = \len{\A_1} +
\len{\A_2}$ and $\len{\overline{\A}} = \len{\A}$, thus the automata
for the boolean operations, including complementation, can be built in
linear time. This is not very surprising, since linear time
intersection and complementation are also possible for alternating
automata over finite alphabets \cite{ChandraKozenStockmeyer81}.

\section{Antichains and Interpolants for Emptiness}

Unlike the boolean closure properties, showed to be effectively
decidable (Lemma \ref{lemma:closure}), the emptiness problem is
undecidable, even in very simple cases. For instance, if $\Data^\I$ is
the set of positive integers, an ADA can simulate an Alternating
Vector Addition System with States (AVASS) \cite{LazicSchmitz14} using
only atoms $x \geq 0$ and $x = \overline{x} + k$, for $k \in \zed$,
with the classical interpretation of the function symbols on
integers. Since reachability of a control state is undecidable for
AVASS, the emptiness problem is undecidable for ADA.

Consequently, we give up on the guarantee for termination and develop
semi-algorithmic methods that are supposed to be
both: \begin{compactenum}
\item \emph{sound}: given an automaton $\A$, if $L(\A) \neq\emptyset$,
  the procedure will terminate and return a word $w \in L(\A)$), and
%
\item \emph{complete relative to termination}: if the procedure terminates
  without returning such a word, then $L(\A) = \emptyset$. 
\end{compactenum}

Let us fix an automaton $\A = \tuple{\vec{x},Q,\iota,F,\Delta}$ whose
(finite) input event alphabet is $\Sigma$, for the rest of this
section. Given a formula $\phi \in \Form^+(Q,\vec{x})$ and an input
event $a \in \Sigma$, we define the \emph{post-image} function
$\Post{\A}(\phi,a) \equiv \exists \overline{\vec{x}} ~.~
\Delta(\phi[\overline{\vec{x}}/\vec{x}], a) \in \Form^+(Q,\vec{x})$,
mapping each formula in $\Form^+(Q,\vec{x})$ to a formula defining the
effect of reading $a \in \Sigma$.

We generalize the post-image function to finite sequences of input
events, as follows: $\Post{\A}(\phi,\varepsilon) \equiv \phi$ and
$\Post{\A}(\phi,ua) \equiv \Post{\A}(\Post{\A}(\phi,u),a)$, for any $u
\in \Sigma^*$. Then the emptiness problem for $\A$ becomes: does there
exist $u \in \Sigma^*$ such that the formula $\Accept{\A}(u) \equiv
\Post{\A}(\iota,u) \wedge \bigwedge_{q \in Q \setminus F} (q
\rightarrow \bot)$ is satisfiable ? A na\"ive semi-algorithm
enumerates all finite sequences and checks the satisfiability of
$\Accept{\A}(u)$ for each $u \in \Sigma^*$, using a decision procedure
for the theory $\theory(\sig,\I)$.

Since no boolean variable from $Q$ occurs under negation in $\phi$, it
is easy to prove the following monotonicity property: given two
formulae $\phi,\psi \in \Form^+(Q,\vec{x})$ if $\phi \models \psi$
then $\Post{\A}(\phi,u) \models \Post{\A}(\psi,u)$, for any $u \in
\Sigma^*$. This suggest an improvement of the above semi-algorithm,
that enumerates and stores only a set $U \subseteq \Sigma^*$ for which
$\set{\Post{\A}(\phi,u) \mid u \in U}$ forms an
\emph{antichain}\footnote{Given a partial order $(D,\preceq)$ an
  antichain is a set $A \subseteq D$ such that $a \not\preceq b$ for
  any $a,b \in A$.} w.r.t. the entailment partial order. This is
because, for any $u,v \in \Sigma^*$, if $\Post{\A}(\iota,u) \models
\Post{\A}(\iota,v)$ and $\Accept{\A}(uw)$ is satisfiable, then
$\Post{\A}(\iota,uw) \models \Post{\A}(\iota,vw)$, thus
$\Accept{\A}(vw)$ is satisfiable as well, and there is no need for
$u$, since the non-emptiness of $\A$ can be proved using $v$
alone. However, in practice, the antichain based semi-algorithm
diverges in a large number of cases, since, in many interpretations,
there exist infinite antichains of formulae\footnote{For instance,
  when $\Data^\I = \nat$, an infinite antichain is $q \wedge x \teq 0,
  q \wedge x \teq 1, \ldots$}.

A \emph{safety invariant} for $\A$ is a function $\Inv : (Q \mapsto
\booli) \rightarrow 2^{\vec{x} \mapsto \Data^\I}$ such that, for every
boolean valuation $\beta : Q \rightarrow \booli$, every valuation
$\nu : \vec{x} \mapsto \Data^\I$ of the data
variables and every finite sequence $u \in \Sigma^*$ of input events: \begin{compactenum}
%% \item $\beta \models \iota \Rightarrow \nu_0 \in \Inv(\beta)$, where
%%   $\nu_0(x) = \mathbf{0}$, for all $x \in \vec{x}$.
%
\item\label{it1:inv} $\beta \cup \nu \models \Post{\A}(\iota,u)
  \Rightarrow \nu \in \Inv(\beta)$, and
%
\item\label{it2:inv} $\nu \in \Inv(\beta) \Rightarrow \beta \cup \nu
  \not\models \Accept{\A}(u)$.
\end{compactenum}
If $\Inv$ satisfies only the first point above, we call it simply an
\emph{invariant}. Intuitively, a safety invariant maps every boolean
valuation into a set of data valuations, that contains the initial
configuration $\iota$, in which the data variables are unconstrained
and over-approximates the set of reachable valuations (\ref{it1:inv}),
while excluding those valuations that satisfying the acceptance
condition (\ref{it2:inv}).

\begin{lemma}\label{lemma:safety-invariant}
  For any automaton $\A$, we have $L(\A)
= \emptyset$ iff $\A$ has a safety invariant. 
\end{lemma}
\proof{ Let $\A = \tuple{\vec{x},Q,\iota,F,\Delta}$ in the following.
  ``$\Leftarrow$'' This direction is trivial. ``$\Rightarrow$'' We
  define $\Inv : (Q \mapsto \booli) \rightarrow 2^{\vec{x} \mapsto
    \Data^\I}$ as follows. For each $\beta : Q \rightarrow \booli$,
  let $\Inv(\beta) = \{\nu : \vec{x} \rightarrow \Data^\I \mid \exists
  u \in \Sigma^* ~.~ \beta\cup\nu \models
  \Post{\A}(\iota,u)\}$. Checking that $\Inv$ is a safety invariant is
  straightforward. \qed}

Turning back to the issue of divergence of language emptiness
semi-algorithms in the case $L(\A) = \emptyset$, we can observe that
an enumeration of input sequences $u_1,u_2,\ldots \in \Sigma^*$ can
stop at step $k$ as soon as $\bigvee_{i=1}^k \Post{\A}(\iota,u_i)$
defines\footnote{ A formula $\phi(Q,\vec{x})$ defines $\Inv$ iff for
  all $\beta: Q \rightarrow \booli$ and $\nu : \vec{x} \rightarrow
  \Data^\I$: $\beta\cup\nu \models \phi \iff \nu \in \Inv(\beta)$. } a
safety invariant for $\A$. Although this condition can be effectively
checked using a decision procedure for the theory $\theory(\sig,\I)$,
there is no guarantee that this check will ever succeed.

The solution we adopt is the use of \emph{abstraction} to ensure
termination of invariant computations. However, it is worth pointing
out from the start that abstraction will allow us to build invariants
which are not necessarily safety invariants. To converge towards
meeting the latter condition, we shall resort to \emph{counterexample
  guided abstraction refinement} (CEGAR). 

Formally, let $\preds$ be a finite set of formulae with variables from
$Q \cup \vec{x}$, such that $\bot \in \preds$ and the variables in $Q$
can occur negated in some $\phi \in \preds$. We assume that $\preds$
is fixed for now, and refer to these formulae as \emph{predicates}.
Given a formula $\phi$, we denote by $\abs{\phi} \equiv \bigwedge
\set{\pi \in \preds \mid \phi \models \pi}$ the abstraction of $\phi$
w.r.t. the predicates in $\preds$. The abstract version of the
post-image and acceptance condition are defined as follows:
{\footnotesize\[ \abs{\Post{\A}}(\phi,\varepsilon) \equiv \phi
\hspace*{2mm}
\abs{\Post{\A}}(\phi,ua) \equiv \abs{(\Post{\A}(\abs{\Post{\A}}(\phi,u),a))} 
\hspace*{2mm}
\abs{\Accept{\A}}(u) \equiv \abs{\Post{\A}}(\iota,u) \wedge\!\!\!\bigwedge_{q \in Q \setminus F} 
(q \rightarrow \bot)\]}
\begin{lemma}\label{lemma:abstract-invariant}
  For any bijection $\mu : \nat \rightarrow \Sigma^*$, there exists
  $k>0$ such that $\bigvee_{i=1}^k \abs{\Post{\A}}(\iota,\mu(i))$ defines
  an invariant for $\A$. 
\end{lemma}
\proof{ It is sufficient to show that there exists $k\geq0$ such that for
  all $u \in \Sigma^*$ there exists $i \in [0,k]$ such that
  $\Post{\A}(\iota,u) \models \abs{\Post{\A}}(\iota,\mu(i))$. We have
  $\Post{\A}(\iota,u) \models \abs{\Post{\A}}(\iota,u)$ for all $u \in
  \Sigma^*$. But since $\preds$ is a finite set, also the set
  $\{\abs{\Post{\A}}(\iota,u) \mid u \in \Sigma^*\}$ is finite. Thus
  there exists $k \geq 0$ such that, for all $u \in \Sigma^*$ there
  exists $i \in [0,k]$ such that $\abs{\Post{\A}}(\iota,u) \eqiff
  \abs{\Post{\A}}(\iota,\mu(i))$, which concludes the proof. \qed}

We are left with fulfilling the second point from the definition of a
safety invariant. To this end, suppose that, for a given set $\preds$
of predicates, the invariant $\abs{\Inv}$, defined by the previous
lemma, meets point (\ref{it1:inv}) but not point (\ref{it2:inv}) from
the definition of invariants, where $\Post{\A}$ and $\Accept{\A}$
replace $\abs{\Post{\A}}$ and $\abs{\Accept{\A}}$, respectively. In
other words, there exists a finite sequence $u \in \Sigma^*$ such that
$\nu \in \abs{\Inv}(\beta)$ and $\beta\cup\nu \models
\abs{\Accept{\A}}(u)$, for some boolean $\beta : Q \rightarrow \booli$
and data $\nu : \vec{x} \rightarrow \Data^\I$ valuations. Such
a $u\in\Sigma^*$ is called a \emph{counterexample}.

Once a counterexample $u$ is discovered, there are two
possibilities. Either\begin{inparaenum}[(i)]
\item $\Accept{\A}(u)$ is satisfiable, in which case $L(\A) \neq \emptyset$, or
\item $\Accept{\A}(u)$ is unsatisfiable, in which case $u$ is called
  \emph{spurious}.
\end{inparaenum}
In the first case, our semi-algorithm stops and returns a witness for
non-emptiness, obtained from the satisfying valuation of
$\Accept{\A}(u)$ and in the second case, we must strenghten the
invariant by excluding from $\abs{\Inv}$ all pairs $(\beta,\nu)$ such
that $\beta\cup\nu \models \abs{\Accept{\A}}(u)$. This strenghtening
is carried out by adding to $\preds$ several predicates that are
sufficient to exclude the spurious counterexample.

In general, given an unsatisfiable conjunction $\pi \equiv
\phi_1(X_0,X_1) \wedge \phi_2(X_1,X_2) \wedge \ldots \wedge
\phi_n(X_{n-1},X_n)$ of time-stamped variables $X_i = \set{x_i \mid x
  \in X}$ of any sort, a solution of the \emph{interpolation problem}
$\pi$, simply called an \emph{interpolant}, is a tuple $\tuple{I_0(X),
  I_1(X), \ldots, I_n(X)}$ such that:\begin{inparaenum}[(i)]
\item $I_0 \equiv \top$,  
%
\item $I_{i-1}[X_{i-1}/X] \wedge \phi_i(X_{i-1},X_i) \models
  I_i[X_i/X]$, for all $i \in [1,n]$, and
%
\item $I_n \equiv \bot$. 
\end{inparaenum}
A classical method for abstraction refinement is to add the elements
of the interpolant obtained from a proof of spuriousness to the set of
predicates. This guarantees progress, meaning that the particular
spurious counterexample, from which the interpolant was generated,
will never be revisited in the future. In many practical test cases,
this progress property eventually yields a safety invariant. 

Given a non-empty spurious counterexample $u = a_1\ldots a_n$, where
$n>0$, we consider the following interpolation problem: \[\pi(u)
\equiv \theta_0(Q_0) \wedge \theta_1(Q_0 \cup Q_1,\vec{x}_0 \cup
\vec{x}_1) \wedge \ldots \wedge \theta_n(Q_{n-1} \cup
Q_n,\vec{x}_{n-1} \cup \vec{x}_n) \wedge \theta_{n+1}(Q_n)\] where
$Q_k = \set{q_k \mid q \in Q}$, $k \in [0,n]$ are time-stamped sets of
boolean variables corresponding to the set $Q$ of states of $\A$. The
first conjunct $\theta_0(Q_0) \equiv \iota[Q_0/Q]$ is the initial
configuration of $\A$, with every $q \in \fv{\Bool}{\iota}$ replaced
by $q_0$. The definition of $\theta_k$, $k\in[1,n]$ uses
\emph{replacement sets} $R_\ell \in Q_\ell$, $\ell\in [0,n]$, which
are defined inductively below: \begin{compactitem}
\item $R_0 = \fv{\Bool}{\iota(Q_0)}$, 
%
\item for each $\ell\in[1,n]$: $\theta_\ell \equiv
  \bigwedge_{q_{\ell-1}\in R_{\ell-1}} (q_{\ell-1} \rightarrow
  \Delta(q,a_\ell)[Q_\ell/Q,\vec{x}_{\ell-1}/\overline{\vec{x}},\vec{x}_\ell/\vec{x}])$
  and $R_\ell = \fv{\Bool}{\theta_\ell} \cap Q_\ell$.
\end{compactitem}
Finally, we set $\theta_{n+1}(Q_n) \equiv \bigwedge_{q \in Q \setminus
  F} (q_n \rightarrow \bot)$. The intuition is that $\theta_0, \ldots,
\theta_n$ simulates the run of $\A$ over $u$ and $\theta_{n+1}$ is the
part of the acceptance condition which forces the last remaining
non-final states to be false. 

We recall that a run of $\A$ over $u$ is a sequence $\phi_0(Q),
\phi_1(Q,\vec{x}_0\cup\vec{x}_1), \ldots,
\phi_n(Q,\vec{x}_0\cup\ldots\cup\vec{x}_n)$, where $\phi_0$ is the
initial configuration $\iota$ and for each $k>0$, $\phi_k$ is obtained
from $\phi_{k-1}$ by replacing each state $q \in
\fv{\Bool}{\phi_{k-1}}$ by the formula $\Delta(q,a_k)$ given by the
transition function of $\A$. The main reason behind the above
definition of the interpolation problem is that we would like to
obtain an interpolant $\tuple{\top,I_1(Q), I_2(Q,\vec{x}), \ldots,
  I_{n}(Q,\vec{x}),\bot}$ whose formulae \emph{combine states with
  the data constraints that must hold locally}, whenever the control
reaches a certain boolean configuration. This association of states
with data valuations is tantamount to defining efficient
semi-algorithms, based on lazy abstraction \cite{HJMS02}. Observe
that, because the states are replaced with transition formulae when
moving one step in a run, the formulae thus produced lose track of the
control history and are not directly suitable to producing
interpolants that can be applied locally. Moreover, the abstraction
defined by the interpolants generated in this way can
\emph{over-approximate the control structure} of an automaton, in
addition to the sets of data values encountered throughout its runs.

The correctness of this interpolation-based abstraction refinement
setup is captured by the progress property below, which guarantees
that adding the formulae of an interpolant for $\pi(u)$ to the set
$\preds$ of predicates suffices to exclude $u$ from future searches.

\begin{lemma}\label{lemma:progress}
  Given a non-empty sequence of input events $u \in \Sigma^*$ such
  that $\Accept{\A}(u)$ is unsatisfiable, then the following
  hold: \begin{compactenum}
  \item\label{it1:progress} $\pi(u)$ is unsatisfiable, and
    %
  \item\label{it2:progress} if $\tuple{\top,I_1,\dots,I_n,\bot}$ is an
    interpolant for $\pi(u)$ and $I_i \in \preds$, for all
    $i\in[1,n]$, then $\abs{\Accept{\A}}(u)$ is unsatisfiable.
  \end{compactenum}
\end{lemma}
\proof{
  
\qed}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\bibliographystyle{abbrv} \bibliography{refs}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\end{document}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
